{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matrixprofile import *\n",
    "from matrixprofile.discords import discords\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.io import arff\n",
    "from binarytree import Node\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from scipy.stats import entropy\n",
    "from math import log, e\n",
    "import pydotplus\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VERSIONE CON USO DEI MOTIF,DISCORD O ENTRAMBI E CON MODULARITA' NELLA RIMOZIONE DEI CANDIDATI GIA SCELTI\n",
    "# AGGIUNTA ANCHE LA FUNZIONE MIA PER SCEGLIERE IL BEST ATTRIBUTE E RELATIVO VALORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_all(Ts,window_size): #fornita la Ts calcola e restituisce mp, motifs, motifs_distances e discords\n",
    "    Ts=Ts[0:127] #rimuovo l'attributo \"classe\"\n",
    "\n",
    "    dfMP = pd.DataFrame(Ts).astype(float) # genero Dframe per lavorarci su, DA CAPIRE PERCHE SERVE FLOAT\n",
    "    mp, mpi = matrixProfile.stomp(dfMP[0].values,window_size) #OK STOMP\n",
    "\n",
    "    #PREPARO TUPLA DA PASSARE ALLA FUN MOTIF (RICHIEDE TUPLA FATTA DA MP E MPI)\n",
    "    tupla=mp,mpi\n",
    "\n",
    "    mot, motif_dist  =motifs.motifs(dfMP[0].values,tupla,2)\n",
    "\n",
    "    #CALCOLO MOTIFS\n",
    "   # print('Motifs starting position: '+str(mot)+ ' Motifs values (min distances): '+str(motif_dist))\n",
    "   # print(\" \")\n",
    "\n",
    "    #CALCOLO DISCORDS\n",
    "    dis= discords(mp,window_size,2)\n",
    "    #print('Discords starting position: '+str(dis))\n",
    "    \n",
    "    tupla=mp,mot,motif_dist,dis\n",
    "    return tupla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ogni motif e identificato da almeno due indici di partenza nella Ts, ne prendo uno solo rappresentativo\n",
    "#genero poi struttura contenente gli indici di partenza di tutti i candidati\n",
    "\n",
    "def candidateFilter(CandidatesList): \n",
    "    counterNumberMotif=0\n",
    "    counterNumberDiscord=0\n",
    "    l2=np.array([])\n",
    "    for i in range (len(CandidatesList['Motif'])): #per ogni entry (per ogni record)\n",
    "        numMotif=len(CandidatesList['Motif'].iloc[i])\n",
    "        numDiscord=len(CandidatesList['Discord'].iloc[i])\n",
    "        counterNumberDiscord+=numDiscord\n",
    "        #print(numMotif)\n",
    "        for j in range (numMotif): # per ogni lista di motif\n",
    "            l1=CandidatesList['Motif'].iloc[i] #prima lista\n",
    "            l2=np.append(l2,l1[j][0]) #prendo primo valore di ogni lista\n",
    "            counterNumberMotif+=1\n",
    "            \n",
    "    \n",
    "        CandidatesList['Motif'].iloc[i]=l2\n",
    "        l2=np.array([]) #svuoto array\n",
    "    \n",
    "    return CandidatesList,counterNumberMotif,counterNumberDiscord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "def buildCandidatesUsedList(CandidatesList,numberOfMotif,numberOfDiscord):\n",
    "    CandidatesUsedList=pd.DataFrame(columns=['Used'],index=range(0,numberOfMotif+numberOfDiscord))\n",
    "    boolList=[False] * (numberOfMotif+numberOfDiscord)\n",
    "    CandidatesUsedList['Used']= boolList\n",
    "    return CandidatesUsedList\n",
    "                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataStructures(df,window_size):\n",
    "    #trasformo da stringa a numero il campo target \n",
    "    le = LabelEncoder()\n",
    "    num_classes = le.fit_transform(df['target'])\n",
    "    df['target']=num_classes\n",
    "    df['TsIndex']=np.arange(len(df))\n",
    "    window_size=5\n",
    "    #diz={'Motif':[],'Motif-Dist':[],'Discord':[]}\n",
    "    diz={'Motif':[],'Discord':[]}\n",
    "\n",
    "    #CALCOLO MOTIF E DISCORD E LI INSERISCO NEL DIZIONARIO\n",
    "    for i in range(len(df)):\n",
    "        Ts = np.array(df.iloc[i][0:-2].values)\n",
    "        mp,mot,motif_dist,dis = retrieve_all(Ts,window_size)\n",
    "        diz['Motif'].insert(i, mot)\n",
    "        diz['Discord'].insert(i, dis)\n",
    "\n",
    "    #GENERO DFRAME DA DIZIONARIO\n",
    "\n",
    "    CandidatesList = pd.DataFrame(diz)\n",
    "    CandidatesList,numberOfMotif,numberOfDiscord=candidateFilter(CandidatesList)\n",
    "    CandidatesUsedList=buildCandidatesUsedList(CandidatesList,numberOfMotif,numberOfDiscord)\n",
    "\n",
    "    print('Candidati estratti')\n",
    "    #print(MotifsList['Motif'])\n",
    "    print(CandidatesList)\n",
    "    print(numberOfMotif,numberOfDiscord)\n",
    "    print(CandidatesUsedList)\n",
    "    \n",
    "    return mp,CandidatesList,numberOfMotif,numberOfDiscord,CandidatesUsedList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#per ogni Ts calcolo Dprofile con ogni candidato e inserisco la distanza minima con candidato i-esimo nella colonna i-esima\n",
    "def computeSubSeqDistance(dataset,CandidatesList):\n",
    "    \n",
    "    #quantifico il num di candidati e in base a tale valore genero colonne per dfForDTree\n",
    "    numberOfCandidates=0\n",
    "    for i in range(len(CandidatesList)):\n",
    "            numberOfCandidates+=len(CandidatesList['Motif'].loc[i])\n",
    "            numberOfCandidates+=len(CandidatesList['Discord'].loc[i])\n",
    "    columnsList=np.arange(numberOfCandidates)\n",
    "    columnsList2=list()\n",
    "    lastAttribute=['TsIndex','class']\n",
    "    prefix='cand'\n",
    "    for i in columnsList:\n",
    "        columnsList2.append(prefix+str(i)) \n",
    "    columnsList2.append('TsIndex')\n",
    "    columnsList2.append('class')\n",
    "    dfForDTree=pd.DataFrame(columns=columnsList2,index=range(0,len(dataset)))\n",
    "\n",
    "    #per ogni Ts, scandisco ogni candidato e calcolo la distanza minore \n",
    "    for i in range(len(dataset)):\n",
    "        #acquisisco la Ts\n",
    "        TsToCompare = np.array(dataset.iloc[i].values) \n",
    "        classValue=TsToCompare[128]\n",
    "        TsToCompare=TsToCompare[0:128]\n",
    "        dfForDTree['TsIndex'].iloc[i]=i\n",
    "        dfForDTree['class'].iloc[i]=classValue\n",
    "        counter=0\n",
    "        #scandisco e calcolo distanza dai motif\n",
    "        for j in range(len(CandidatesList)):\n",
    "            numMotif=len(CandidatesList['Motif'].iloc[j])\n",
    "            numDiscord=len(CandidatesList['Discord'].iloc[j])\n",
    "            for k in range(numMotif):\n",
    "                l1=CandidatesList['Motif'].iloc[j] #lista di indice i in motifDiscordList\n",
    "                startingIndex=l1[k] #indice di inizio del motif\n",
    "                TsContainingCandidateShapelet = np.array(dataset.iloc[j].values) #Ts contenente candidato shapelet\n",
    "                Dp=distanceProfile.massDistanceProfile(TsContainingCandidateShapelet,int(startingIndex),window_size,TsToCompare)\n",
    "                minValueFromDProfile=min(Dp[0]) #Dp[0] contiene il Dp effettivo\n",
    "                dfForDTree[prefix+str(counter)].iloc[i]=minValueFromDProfile\n",
    "                counter+=1\n",
    "            for k in range(numDiscord):\n",
    "                l1=CandidatesList['Discord'].iloc[j] #lista di indice i in motifDiscordList\n",
    "                startingIndex=l1[k] #indice di inizio del motif\n",
    "                TsContainingCandidateShapelet = np.array(dataset.iloc[j].values) #Ts contenente candidato shapelet\n",
    "                Dp=distanceProfile.massDistanceProfile(TsContainingCandidateShapelet,int(startingIndex),window_size,TsToCompare)\n",
    "                minValueFromDProfile=min(Dp[0]) #Dp[0] contiene il Dp effettivo\n",
    "                dfForDTree[prefix+str(counter)].iloc[i]=minValueFromDProfile\n",
    "                counter+=1\n",
    "        \n",
    "   # print(counter)    \n",
    "    return dfForDTree #columnsList2 restituito per generare poi dFrame in \"Split\" (struttura dframe)\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset (dframe): nella riga i: indice della ts di appartenenza, distanza tra candidato e Ts, e classe di appartenenza di Ts\n",
    "#calcola entropia di un dataset basandosi sul num di classi esistenti\n",
    "def computeEntropy(dataset):\n",
    "    value,counts = np.unique(dataset['class'], return_counts=True)\n",
    "    actualEntropy=entropy(counts, base=2)\n",
    "    return actualEntropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calcola il gain tra entropia nodo padre e sommatoria entropia nodi figli (GAIN CALCOLATO SUL VALORE DELL'ATTRIBUTO)\n",
    "def computeGain(entropyParent,LenDatasetParent,Dleft,Dright):\n",
    "    entropyLeft=computeEntropy(Dleft)\n",
    "    entropyRight=computeEntropy(Dright)\n",
    "    gain=entropyParent\n",
    "    summation=( ((len(Dleft)/LenDatasetParent)*entropyLeft) +  ((len(Dright)/LenDatasetParent)*entropyRight) )\n",
    "    #print('entropyParent: '+str(entropyParent))\n",
    "    #print('SUMMATION: '+str(summation))\n",
    "    gain=gain-summation\n",
    "    return gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLIT SLAVE\n",
    "#effettua lo split del dataset sul attributo e valore fornito\n",
    "def split(dataset,attribute,value): \n",
    "    columnsList=dataset.columns.values\n",
    "    dizLeft=pd.DataFrame(columns=columnsList)\n",
    "    dizRight=pd.DataFrame(columns=columnsList)\n",
    "    for i in range(len(dataset)):\n",
    "        if dataset.iloc[i][attribute] < value:\n",
    "            dizLeft = dizLeft.append(dataset.iloc[i], ignore_index=True)\n",
    "        else:\n",
    "            dizRight = dizRight.append(dataset.iloc[i], ignore_index=True)\n",
    "    return dizLeft, dizRight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# riceve dframe con mutual_information(gain) e in base al candidatesGroup scelto, determina il miglior attributo su cui splittare\n",
    "# che non è stato ancora utilizzato\n",
    "def getBestIndexAttribute(vecMutualInfo,candidatesGroup,CandidatesUsedListTrain,numberOfMotif,numberOfDiscord):\n",
    "        \n",
    "    #ordino i candidati in base a gain decrescente\n",
    "    \n",
    "    vecMutualInfo=vecMutualInfo.sort_values(by='gain',ascending = False)\n",
    "    \n",
    "    #scandisco i candidati fino a trovare il candidato con miglior gain che non è ancora stato usato\n",
    "    \n",
    "    bestIndexAttribute=-1\n",
    "    i=0\n",
    "    \n",
    "    #cicla fin quando trova candidato libero con gain maggiore\n",
    "    while(bestIndexAttribute==-1 and i<len(vecMutualInfo)):    \n",
    "        attributeToVerify=int(vecMutualInfo.iloc[i]['attribute'])\n",
    "        if(CandidatesUsedListTrain.iloc[attributeToVerify]['Used']==False):\n",
    "            bestIndexAttribute=attributeToVerify\n",
    "            splitValue=vecMutualInfo.iloc[i]['splitValue']\n",
    "            CandidatesUsedListTrain.iloc[attributeToVerify]=True #settando a true il candidato scelto, non sarà usato in seguito\n",
    "        else:\n",
    "            i+=1\n",
    "    \n",
    "    return bestIndexAttribute,splitValue\n",
    "            \n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeMutualInfo(datasetForMutual,candidatesGroup,numberOfMotif,numberOfDiscord):\n",
    "    \n",
    "    #definisco lista di indici inserire nella colonna 'attribute'\n",
    "    if(candidatesGroup==0):\n",
    "        candidatesIndex=range(numberOfMotif)\n",
    "        numAttributes=numberOfMotif\n",
    "    elif(candidatesGroup==1):\n",
    "        candidatesIndex=range(numberOfMotif,numberOfMotif+numberOfDiscord)\n",
    "        numAttributes=numberOfDiscord\n",
    "    else:\n",
    "        candidatesIndex=range(numberOfMotif+numberOfDiscord)\n",
    "        numAttributes=numberOfMotif+numberOfDiscord\n",
    "    \n",
    "    columns=datasetForMutual.columns\n",
    "    dframe=pd.DataFrame(columns=['attribute','splitValue','gain'],index=range(len(columns)-1))\n",
    "    entropyParent=computeEntropy(datasetForMutual)\n",
    "\n",
    "    \n",
    "    y=datasetForMutual['class']\n",
    "    \n",
    "    #per ogni attributo, ordino il dframe sul suo valore\n",
    "    #scandisco poi la y e appena cambia il valore di class effettuo uno split, memorizzando il best gain\n",
    "    \n",
    "    for i in range(len(columns)-1):\n",
    "        bestGain=-1\n",
    "        bestvalueForSplit=0\n",
    "        previousClass=-1 #deve essere settato ad un valore non presente nei class value\n",
    "        attribute=columns[i]\n",
    "        datasetForMutual=datasetForMutual.sort_values(by=attribute,ascending = True)    \n",
    "        \n",
    "       \n",
    "        \n",
    "        for j in range(len(y)):\n",
    "            if(j==0):\n",
    "                previousClass=y[j]\n",
    "                continue\n",
    "            else:\n",
    "                if(y[j]!=previousClass):\n",
    "                    testValue=datasetForMutual.iloc[j][attribute]\n",
    "                    Dleft,Dright=split(datasetForMutual,attribute,testValue)\n",
    "                    actualGain=computeGain(entropyParent,len(datasetForMutual),Dleft,Dright)\n",
    "                    if(actualGain > bestGain):\n",
    "                        bestGain=actualGain\n",
    "                        bestvalueForSplit=testValue\n",
    "               \n",
    "                previousClass=y[j] \n",
    "        # memorizzo in posizione i-esima lo split migliore e relativo gain\n",
    "        \n",
    "        dframe.iloc[i]['splitValue']=bestvalueForSplit\n",
    "        dframe.iloc[i]['gain']=bestGain\n",
    "        \n",
    "    \n",
    "    \n",
    "    dframe['attribute']=candidatesIndex\n",
    "    return dframe\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLIT INTERMEDIO\n",
    "#dato il dataset, cerca il miglior attributo e relativo valore (optimal split point) su cui splittare\n",
    "# restituiendo il dataset splittato e i valori trovati\n",
    "def findBestAttributeValue(dataset,candidatesGroup,CandidatesUsedListTrain,numberOfMotif,numberOfDiscord,removeUsedCandidate):\n",
    "    #cerca e restituisce attributo migliore su cui splittaree relativo valore ottimale (optimal split point)\n",
    "    #CANDIDATE GROUP permette di scegliere se usare come candidati 0=motifs 1=discord 2=entrambi\n",
    "    bestGain=0\n",
    "    actualGain=0\n",
    "    bestvalueForSplit=0\n",
    "    y = dataset['class'].values\n",
    "    y=y.astype('int')\n",
    "    entropyParent=computeEntropy(dataset)\n",
    "    \n",
    "    #trovo best Attribute\n",
    "    numAttributes=len(dataset.columns.values)\n",
    "    numAttributes-=2 #tolgo i due attributi TsIndex e class dal Dframe\n",
    "    datasetForMutual=pd.DataFrame()\n",
    "    \n",
    "    #preparo il Dframe da passare a mutual_info_classif, settando se scegliere tra motifs/discord/entrambi\n",
    "    \n",
    "    if(candidatesGroup==0): #solo motifs\n",
    "        dataset=dataset.iloc[:,np.r_[:numberOfMotif]].copy()\n",
    "    elif(candidatesGroup==1):\n",
    "        datasetForMutual=dataset.iloc[:,np.r_[numberOfMotif:numberOfMotif+numberOfDiscord]].copy()\n",
    "    else:\n",
    "        datasetForMutual=dataset.iloc[:,np.r_[:numAttributes]].copy()\n",
    "\n",
    "    datasetForMutual['class']=y\n",
    "    \n",
    "    #calcolo gain e miglior valore di split per ogni attributo\n",
    "    \n",
    "    \n",
    "    vecMutualInfo=computeMutualInfo(datasetForMutual,candidatesGroup,numberOfMotif,numberOfDiscord)\n",
    "    \n",
    "    #se rimuovo candidati, faccio scegliere migliore non ancora utilizzato\n",
    "    \n",
    "    if(removeUsedCandidate==1): \n",
    "        indexBestAttribute,bestValueForSplit=getBestIndexAttribute(vecMutualInfo,candidatesGroup,CandidatesUsedListTrain,numberOfMotif,numberOfDiscord)\n",
    "    else: #se non rimuovo candidati, mi basta prendere il primo\n",
    "        vecMutualInfo=vecMutualInfo.sort_values(by='gain',ascending = False)\n",
    "        print(vecMutualInfo)\n",
    "        indexBestAttribute=vecMutualInfo.iloc[0]['attribute']\n",
    "        bestValueForSplit=vecMutualInfo.iloc[0]['splitValue']\n",
    "        print(indexBestAttribute,bestValueForSplit)\n",
    "    \n",
    "    splitValue=bestValueForSplit\n",
    "    Dleft,Dright=split(dataset,indexBestAttribute,bestValueForSplit)\n",
    "    \n",
    "    \n",
    "    return [indexBestAttribute,splitValue,Dleft,Dright]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLIT MASTER\n",
    "# funzione ricorsiva che implementa la creazione dell'albero di classificazione\n",
    "# memorizza in ogni nodo: attributo, valore attributo su cui splitto, entropia nodo, num pattern\n",
    "# memorizza in ogni foglia: entropia nodo, num pattern, classe nodo\n",
    "\n",
    "# VERSIONE CHE RIMUOVE I CANDIDATI QUANDO VENGONO SCELTI \n",
    "\n",
    "def buildTree(actualNode,dataset,maxDepth, minSamplesLeaf, depth,candidatesGroup,CandidatesUsedListTrain,numberOfMotif,numberOfDiscord,removeUsedCandidate):\n",
    "    #caso base: num pattern < soglia minima || profondità massima raggiunta => genero foglia con media delle classi\n",
    "    #DATASET HA SEMPRE ALMENO UN PATTERN\n",
    "    boolValue=checkIfIsLeaf(dataset)\n",
    "    if(len(dataset)<minSamplesLeaf or depth>=maxDepth or boolValue==True ):\n",
    "        average = sum(dataset['class'].values) / len(dataset['class'].values)\n",
    "        classValue = round(average)\n",
    "        numPattern=len(dataset)\n",
    "        entropy=computeEntropy(dataset)\n",
    "        \n",
    "        nodeInfo=list()\n",
    "        nodeInfo.append(classValue)\n",
    "        nodeInfo.append(numPattern)\n",
    "        nodeInfo.append(entropy)\n",
    "    \n",
    "        actualNode.data=nodeInfo\n",
    "        actualNode.value=-1\n",
    "        actualNode.left=None\n",
    "        actualNode.right=None\n",
    "        #print(dataset['class'])\n",
    "        return \n",
    "    #caso ricorsivo in cui si può splittare\n",
    "    else:\n",
    "        \n",
    "        returnList=findBestAttributeValue(dataset,candidatesGroup,CandidatesUsedListTrain,numberOfMotif,numberOfDiscord,removeUsedCandidate)\n",
    "        indexChosenAttribute=returnList[0]\n",
    "        attributeValue=returnList[1]\n",
    "        Dleft=returnList[2]\n",
    "        Dright=returnList[3]\n",
    "        numPattern=len(dataset)\n",
    "        entropy=computeEntropy(dataset)\n",
    "        attributeList.append(indexChosenAttribute)\n",
    "        \n",
    "        #memorizzo nel nodo l'attributo, il valore e altre info ottenute dallo split\n",
    "        \n",
    "        nodeInfo=list()\n",
    "        nodeInfo.append(attributeValue)\n",
    "        nodeInfo.append(numPattern)\n",
    "        nodeInfo.append(entropy)\n",
    "        actualNode.data=nodeInfo\n",
    "        actualNode.value=(indexChosenAttribute)\n",
    "        \n",
    "        #se possibile richiamo ricorsivamente sul nodo dx e sx figlio\n",
    "        if(len(Dleft)>0):\n",
    "            actualNode.left=Node(indexChosenAttribute)\n",
    "            buildTree(actualNode.left,Dleft,maxDepth, minSamplesLeaf, depth+1,candidatesGroup,CandidatesUsedListTrain,numberOfMotif,numberOfDiscord,removeUsedCandidate)\n",
    "        \n",
    "        if(len(Dright)>0):\n",
    "            actualNode.right=Node(indexChosenAttribute)\n",
    "            buildTree(actualNode.right,Dright,maxDepth, minSamplesLeaf, depth+1,candidatesGroup,CandidatesUsedListTrain,numberOfMotif,numberOfDiscord,removeUsedCandidate)\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verifica se dataset, ha pattern appartenenti ad una sola classe => è gia foglia\n",
    "def checkIfIsLeaf(dataset):\n",
    "    isLeaf=True\n",
    "    entropy=computeEntropy(dataset)\n",
    "    if(entropy>0):\n",
    "        isLeaf=False\n",
    "    return isLeaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#effettua il primo passo dell'algo di generazione dell'albero, richiama ricorsivamente sui figli\n",
    "# VERSIONE CHE NON RIMUOVE I CANDIDATI QUANDO VENGONO SCELTI \n",
    "def startAlgo(dfForDTree,candidatesGroup,CandidatesUsedListTrain,maxDepth,minSamplesLeaf,numberOfMotif,numberOfDiscord,removeUsedCandidate):\n",
    "    \n",
    "    #inizio algo per nodo radice\n",
    "    returnList=findBestAttributeValue(dfForDTree,candidatesGroup,CandidatesUsedListTrain,numberOfMotif,numberOfDiscord,removeUsedCandidate)\n",
    "    indexChosenAttribute=returnList[0]\n",
    "    attributeValue=returnList[1]\n",
    "    Dleft=returnList[2]\n",
    "    Dright=returnList[3]\n",
    "    attributeList.append(indexChosenAttribute)\n",
    "    root=Node(indexChosenAttribute)\n",
    "    numPattern=len(dfForDTree)\n",
    "    entropy=computeEntropy(dfForDTree)\n",
    "        \n",
    "    #memorizzo nel nodo l'attributo, il valore e altre info ottenute dallo split\n",
    "        \n",
    "    nodeInfo=list()\n",
    "    nodeInfo.append(attributeValue)\n",
    "    nodeInfo.append(numPattern)\n",
    "    nodeInfo.append(entropy)\n",
    "    root.data=nodeInfo\n",
    "    \n",
    "    root.left=Node(indexChosenAttribute)\n",
    "    root.right=Node(indexChosenAttribute)\n",
    "    \n",
    "    #chiamata ricorsiva\n",
    "    if(len(Dleft)>0):\n",
    "        buildTree(root.left,Dleft,maxDepth, minSamplesLeaf,1,candidatesGroup,CandidatesUsedListTrain,numberOfMotif,numberOfDiscord,removeUsedCandidate)\n",
    "    if(len(Dright)>0):\n",
    "        buildTree(root.right,Dright,maxDepth, minSamplesLeaf, 1,candidatesGroup,CandidatesUsedListTrain,numberOfMotif,numberOfDiscord,removeUsedCandidate)\n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stampa dell'albero\n",
    "def printAll(Root):\n",
    "    if(Root.left==None and Root.right==None):\n",
    "        print('foglia')\n",
    "    print('Nodo: '+str(Root.value))\n",
    "    df=Root.data\n",
    "    print(df)\n",
    "    print(\"\\n\")\n",
    "    if(Root.left!=None):\n",
    "        printAll(Root.left)\n",
    "    if(Root.right!=None):\n",
    "        printAll(Root.right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(testDataset,root):\n",
    "    print('START PRED')\n",
    "    #preparo dataset \n",
    "    numAttributes=len(testDataset.columns.values)\n",
    "    numAttributes-=2 #per prendere solo gli attributi utili a xTest\n",
    "    yTest=testDataset.iloc[:]['class'].values\n",
    "    yPredicted=np.zeros( len(yTest) )\n",
    "    xTest=testDataset.iloc[:,np.r_[:numAttributes]]\n",
    "    \n",
    "    #effettuo predizione per ogni pattern\n",
    "    \n",
    "    for i in range(len(xTest)):\n",
    "        pattern=xTest.iloc[i]\n",
    "        yPredicted[i]= treeExplorer(pattern,root)\n",
    "    \n",
    "    yTest = yTest.astype(int)\n",
    "    yPredicted = yPredicted.astype(int)\n",
    "    \n",
    "    return yTest,yPredicted\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treeExplorer(pattern,node):\n",
    "    #caso base, node è foglia\n",
    "    if(node.value==-1):\n",
    "        return int(node.data[0])\n",
    "    else:\n",
    "    #caso ricorsivo\n",
    "        attr='cand'+str(node.value)\n",
    "        if(pattern[attr] < node.data[0]):\n",
    "            return treeExplorer(pattern,node.left)\n",
    "        else:\n",
    "            return treeExplorer(pattern,node.right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeSubSeqDistanceForTest(datasetTest,datasetTrain,attributeList,CandidatesList,numberOfMotif,numberOfDiscord):\n",
    "    #quantifico il num di candidati usati dall'albero e in base a tale valore genero colonne per dfForDTree\n",
    "      #quantifico il num di candidati e in base a tale valore genero colonne per dfForDTree\n",
    "    columnsList2=list()\n",
    "    prefix='cand'\n",
    "    for i in attributeList:\n",
    "        columnsList2.append(prefix+str(i)) \n",
    "    columnsList2.append('TsIndex')\n",
    "    columnsList2.append('class')\n",
    "    dfForDTree=pd.DataFrame(columns=columnsList2,index=range(0,len(datasetTest)))\n",
    "\n",
    "    #per ogni Ts, scandisco ogni candidato e calcolo la distanza minore \n",
    "    for i in range(len(datasetTest)):\n",
    "        #acquisisco la Ts\n",
    "        TsToCompare = np.array(datasetTest.iloc[i].values) \n",
    "        classValue=TsToCompare[128]\n",
    "        TsToCompare=TsToCompare[0:128]\n",
    "        dfForDTree['TsIndex'].iloc[i]=i\n",
    "        dfForDTree['class'].iloc[i]=classValue\n",
    "        counter=0\n",
    "        #scandisco e calcolo distanza dai motif\n",
    "        for z in range(len(attributeList)):\n",
    "            candidateIndex=attributeList[z]\n",
    "            counter=0\n",
    "            for j in range(len(CandidatesList)):\n",
    "                numMotif=len(CandidatesList['Motif'].iloc[j])\n",
    "                numDiscord=len(CandidatesList['Discord'].iloc[j])\n",
    "                for k in range(numMotif):\n",
    "                    if(counter==candidateIndex):\n",
    "                        l1=CandidatesList['Motif'].iloc[j] #lista di indice i in motifDiscordList\n",
    "                        startingIndex=l1[k] #indice di inizio del motif\n",
    "                        TsContainingCandidateShapelet = np.array(datasetTrain.iloc[j].values) #Ts contenente candidato shapelet\n",
    "                        Dp=distanceProfile.massDistanceProfile(TsContainingCandidateShapelet,int(startingIndex),window_size,TsToCompare)\n",
    "                        minValueFromDProfile=min(Dp[0]) #Dp[0] contiene il Dp effettivo\n",
    "                        dfForDTree[prefix+str(counter)].iloc[i]=minValueFromDProfile\n",
    "                    counter+=1\n",
    "                        \n",
    "                for k in range(numDiscord):\n",
    "                    if(counter==candidateIndex):\n",
    "                        l1=CandidatesList['Discord'].iloc[j] #lista di indice i in motifDiscordList\n",
    "                        startingIndex=l1[k] #indice di inizio del motif\n",
    "                        TsContainingCandidateShapelet = np.array(datasetTrain.iloc[j].values) #Ts contenente candidato shapelet\n",
    "                        Dp=distanceProfile.massDistanceProfile(TsContainingCandidateShapelet,int(startingIndex),window_size,TsToCompare)\n",
    "                        minValueFromDProfile=min(Dp[0]) #Dp[0] contiene il Dp effettivo\n",
    "                        dfForDTree[prefix+str(counter)].iloc[i]=minValueFromDProfile\n",
    "                    counter+=1\n",
    "                    \n",
    "\n",
    "\n",
    "\n",
    "    le = LabelEncoder()        \n",
    "    num_classes = le.fit_transform(dfForDTree['class'])\n",
    "    dfForDTree['class']=num_classes\n",
    "            \n",
    "    return dfForDTree #columnsList2 restituito per generare poi dFrame in \"Split\" (struttura dframe)\n",
    "                \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidati estratti\n",
      "            Motif    Discord\n",
      "0     [9.0, 26.0]   [61, 27]\n",
      "1   [105.0, 54.0]   [8, 119]\n",
      "2    [17.0, 40.0]    [31, 1]\n",
      "3    [48.0, 12.0]   [23, 86]\n",
      "4          [27.0]   [38, 62]\n",
      "5    [45.0, 13.0]  [119, 26]\n",
      "6     [7.0, 37.0]   [98, 76]\n",
      "7     [2.0, 24.0]    [36, 8]\n",
      "8     [1.0, 29.0]   [23, 32]\n",
      "9     [50.0, 0.0]   [38, 59]\n",
      "10   [11.0, 17.0]   [80, 23]\n",
      "11    [31.0, 7.0]  [114, 54]\n",
      "12         [53.0]   [61, 10]\n",
      "13    [79.0, 6.0]  [105, 38]\n",
      "14         [59.0]    [98, 8]\n",
      "15    [2.0, 45.0]     [1, 8]\n",
      "16    [28.0, 3.0]    [5, 88]\n",
      "17   [14.0, 35.0]  [118, 85]\n",
      "18    [13.0, 3.0]   [111, 8]\n",
      "19    [19.0, 6.0]   [92, 35]\n",
      "20   [19.0, 39.0]   [26, 70]\n",
      "21         [26.0]   [13, 35]\n",
      "22   [18.0, 22.0]   [59, 25]\n",
      "23   [27.0, 42.0]  [32, 104]\n",
      "24    [8.0, 28.0]    [4, 95]\n",
      "25         [16.0]   [87, 20]\n",
      "26   [67.0, 59.0]   [33, 83]\n",
      "27   [16.0, 39.0]   [75, 99]\n",
      "28   [11.0, 41.0]   [47, 39]\n",
      "29    [6.0, 15.0]  [117, 51]\n",
      "55 60\n",
      "      Used\n",
      "0    False\n",
      "1    False\n",
      "2    False\n",
      "3    False\n",
      "4    False\n",
      "..     ...\n",
      "110  False\n",
      "111  False\n",
      "112  False\n",
      "113  False\n",
      "114  False\n",
      "\n",
      "[115 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "#ACQUISISCO STRUTTURE DATI DEL TRAINING SET\n",
    "dataset = arff.loadarff('CBF/CBF_TRAIN.arff')\n",
    "dfTrain=pd.DataFrame(dataset[0])\n",
    "window_size=5\n",
    "mpTrain,CandidatesListTrain,numberOfMotifTrain,numberOfDiscordTrain,CandidatesUsedListTrain=getDataStructures(dfTrain,window_size)\n",
    "dfForDTree=computeSubSeqDistance(dfTrain,CandidatesListTrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "     ____54___\n",
      "    /         \\\n",
      "  _23         _41\n",
      " /   \\       /   \\\n",
      "-1    -1    -1    -1\n",
      "\n",
      "[54, 23, 41]\n",
      "Nodo: 54\n",
      "[0.8552925624430023, 15, 1.429473298359841]\n",
      "\n",
      "\n",
      "Nodo: 23\n",
      "[0.47488075680566655, 9, 0.7642045065086203]\n",
      "\n",
      "\n",
      "foglia\n",
      "Nodo: -1\n",
      "[0.0, 2, 0.0]\n",
      "\n",
      "\n",
      "foglia\n",
      "Nodo: -1\n",
      "[1.0, 7, 0.0]\n",
      "\n",
      "\n",
      "Nodo: 41\n",
      "[0.5398349853663161, 6, 0.9182958340544894]\n",
      "\n",
      "\n",
      "foglia\n",
      "Nodo: -1\n",
      "[0.0, 3, 0.0]\n",
      "\n",
      "\n",
      "foglia\n",
      "Nodo: -1\n",
      "[1.0, 3, 0.9182958340544894]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#COSTRUISCO DECISION TREE\n",
    "candidatesGroup=2\n",
    "albero=None\n",
    "maxDepth=3\n",
    "minSamplesLeaf=5\n",
    "attributeList=list()\n",
    "removeUsedCandidate=1\n",
    "albero=startAlgo(dfForDTree[:15],candidatesGroup,CandidatesUsedListTrain,maxDepth,minSamplesLeaf,numberOfMotifTrain,numberOfDiscordTrain,removeUsedCandidate)\n",
    "print(albero)\n",
    "print(attributeList)\n",
    "printAll(albero)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       cand23    cand41    cand54 TsIndex  class\n",
      "0    0.811639  0.348092   1.05526       0      2\n",
      "1     1.14691  0.654809  0.645873       1      0\n",
      "2    0.208966  0.980266  0.676511       2      2\n",
      "3     1.01019  0.581196  0.471751       3      0\n",
      "4    0.241518  0.535538  0.750992       4      1\n",
      "5    0.753613   0.85285  0.351616       5      0\n",
      "6    0.393297   1.01561  0.523738       6      2\n",
      "7    0.523547  0.909661  0.365032       7      2\n",
      "8    0.577218  0.526287  0.740144       8      2\n",
      "9    0.522804  0.374918  0.413701       9      2\n",
      "10   0.873595   0.49644  0.188515      10      1\n",
      "11   0.415998  0.859818  0.508985      11      0\n",
      "12   0.941051  0.200067    1.0561      12      2\n",
      "13   0.435161  0.793817  0.883712      13      0\n",
      "14    0.44236  0.923155  0.953718      14      2\n",
      "15    0.33185  0.518697  0.378107      15      0\n",
      "16   0.525766  0.730099  0.479957      16      0\n",
      "17   0.708996  0.763913   1.07693      17      2\n",
      "18    0.81231  0.332231  0.579711      18      1\n",
      "19   0.631053  0.833203  0.510394      19      0\n",
      "20    0.77702  0.742756  0.821435      20      1\n",
      "21   0.983434  0.785903  0.509016      21      2\n",
      "22  0.0941102  0.987033  0.483102      22      2\n",
      "23    1.16861   0.73676  0.738827      23      0\n",
      "24   0.323973   1.07861  0.597686      24      1\n",
      "25   0.964426  0.273555  0.676821      25      1\n",
      "26   0.910214   1.00698  0.631644      26      1\n",
      "27   0.714058  0.358457   0.65646      27      1\n",
      "28   0.783961  0.425886  0.807426      28      2\n",
      "29   0.816137   1.11511  0.279031      29      1\n",
      "30   0.180543  0.459917  0.638588      30      0\n",
      "31   0.930173  0.835057  0.628123      31      0\n",
      "32   0.356285  0.410429  0.658583      32      0\n",
      "33   0.839543  0.828149  0.962821      33      0\n",
      "34   0.846359  0.584275  0.542963      34      2\n",
      "35   0.622983  0.830152   0.65597      35      2\n",
      "36   0.720214  0.402436  0.503875      36      2\n",
      "37   0.814098   1.02597  0.653324      37      0\n",
      "38   0.909872   1.11384  0.953728      38      2\n",
      "39   0.508821  0.670674  0.564755      39      0\n",
      "40   0.667204  0.689045  0.486846      40      2\n",
      "41   0.814209  0.660219   0.76598      41      0\n",
      "42    1.03566  0.585417   0.57066      42      1\n",
      "43   0.768984  0.795547  0.806863      43      1\n",
      "44   0.367421  0.890067  0.631795      44      0\n",
      "45   0.398844  0.763852  0.935151      45      1\n",
      "46   0.426566  0.573359  0.751204      46      2\n",
      "47   0.979851  0.752588  0.860304      47      2\n",
      "48   0.510054  0.740791  0.733624      48      0\n",
      "49   0.598389  0.950593  0.666701      49      2\n"
     ]
    }
   ],
   "source": [
    "#GENERO STRUTTURE DATI PER TEST SET\n",
    "dataset2 = arff.loadarff('CBF/CBF_TEST.arff')\n",
    "window_size=5\n",
    "dfTest = pd.DataFrame(dataset2[0]) #30 record su matrice da 128 attributi + 'b': classe appartenenza  \n",
    "dfTest=dfTest.iloc[50:100] #ne prendo 50 altrimenti impiega tempo troppo lungo, sono 900 record totali\n",
    "\n",
    "attributeList=sorted(attributeList)\n",
    "dfForDTreeTest=computeSubSeqDistanceForTest(dfTest,dfTrain,attributeList,CandidatesListTrain,numberOfMotifTrain,numberOfDiscordTrain) \n",
    "print(dfForDTreeTest)\n",
    "#CONTROLLA, DOVRRBBE ESSERE GIUSTO COSI, SE USO COMPUTE NORMALE CON dfTest SBAGLIO DATASET DI RIFERIMENTO \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START PRED\n",
      "2 0\n",
      "0 1\n",
      "2 0\n",
      "0 1\n",
      "1 0\n",
      "0 1\n",
      "2 0\n",
      "2 1\n",
      "2 1\n",
      "2 1\n",
      "1 1\n",
      "0 0\n",
      "2 0\n",
      "0 1\n",
      "2 1\n",
      "0 0\n",
      "0 1\n",
      "2 1\n",
      "1 1\n",
      "0 1\n",
      "1 1\n",
      "2 1\n",
      "2 0\n",
      "0 1\n",
      "1 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "2 1\n",
      "1 1\n",
      "0 0\n",
      "0 1\n",
      "0 0\n",
      "0 1\n",
      "2 1\n",
      "2 1\n",
      "2 1\n",
      "0 1\n",
      "2 1\n",
      "0 1\n",
      "2 1\n",
      "0 1\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "2 0\n",
      "2 1\n",
      "0 1\n",
      "2 1\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.28      0.32        18\n",
      "           1       0.27      0.83      0.41        12\n",
      "           2       0.00      0.00      0.00        20\n",
      "\n",
      "    accuracy                           0.30        50\n",
      "   macro avg       0.22      0.37      0.24        50\n",
      "weighted avg       0.20      0.30      0.21        50\n",
      "\n",
      "Accuracy 0.3\n",
      "F1-score [0.32258065 0.40816327 0.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Allen\\softwaretesi1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 5, 13,  0],\n",
       "       [ 2, 10,  0],\n",
       "       [ 6, 14,  0]], dtype=int64)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#EFFETTUO PREDIZIONE E MISURO RISULTATO\n",
    "\n",
    "yTest,yPredicted=predict(dfForDTreeTest,albero)\n",
    "\n",
    "\n",
    "\n",
    "for a,b in zip(yTest,yPredicted):\n",
    "    print(a,b)\n",
    "    \n",
    "print(type(yPredicted))\n",
    "print(type(yTest))\n",
    "    \n",
    "print(classification_report(yTest, yPredicted))\n",
    "print('Accuracy %s' % accuracy_score(yTest, yPredicted))\n",
    "print('F1-score %s' % f1_score(yTest, yPredicted, average=None))\n",
    "confusion_matrix(yTest, yPredicted)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
