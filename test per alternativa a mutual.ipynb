{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matrixprofile import *\n",
    "from matrixprofile.discords import discords\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.io import arff\n",
    "from binarytree import Node\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from scipy.stats import entropy\n",
    "from math import log, e\n",
    "import pydotplus\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VERSIONE CON USO DEI MOTIF,DISCORD O ENTRAMBI E CON MODULARITA' NELLA RIMOZIONE DEI CANDIDATI GIA SCELTI\n",
    "# AGGIUNTA ANCHE LA FUNZIONE MIA PER SCEGLIERE IL BEST ATTRIBUTE E RELATIVO VALORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_all(Ts,window_size): #fornita la Ts calcola e restituisce mp, motifs, motifs_distances e discords\n",
    "    Ts=Ts[0:127] #rimuovo l'attributo \"classe\"\n",
    "\n",
    "    dfMP = pd.DataFrame(Ts).astype(float) # genero Dframe per lavorarci su, DA CAPIRE PERCHE SERVE FLOAT\n",
    "    mp, mpi = matrixProfile.stomp(dfMP[0].values,window_size) #OK STOMP\n",
    "\n",
    "    #PREPARO TUPLA DA PASSARE ALLA FUN MOTIF (RICHIEDE TUPLA FATTA DA MP E MPI)\n",
    "    tupla=mp,mpi\n",
    "\n",
    "    mot, motif_dist  =motifs.motifs(dfMP[0].values,tupla,2)\n",
    "\n",
    "    #CALCOLO MOTIFS\n",
    "   # print('Motifs starting position: '+str(mot)+ ' Motifs values (min distances): '+str(motif_dist))\n",
    "   # print(\" \")\n",
    "\n",
    "    #CALCOLO DISCORDS\n",
    "    dis= discords(mp,window_size,2)\n",
    "    #print('Discords starting position: '+str(dis))\n",
    "    \n",
    "    tupla=mp,mot,motif_dist,dis\n",
    "    return tupla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ogni motif e identificato da almeno due indici di partenza nella Ts, ne prendo uno solo rappresentativo\n",
    "#genero poi struttura contenente gli indici di partenza di tutti i candidati\n",
    "\n",
    "def candidateFilter(CandidatesList): \n",
    "    counterNumberMotif=0\n",
    "    counterNumberDiscord=0\n",
    "    l2=np.array([])\n",
    "    for i in range (len(CandidatesList['Motif'])): #per ogni entry (per ogni record)\n",
    "        numMotif=len(CandidatesList['Motif'].iloc[i])\n",
    "        numDiscord=len(CandidatesList['Discord'].iloc[i])\n",
    "        counterNumberDiscord+=numDiscord\n",
    "        #print(numMotif)\n",
    "        for j in range (numMotif): # per ogni lista di motif\n",
    "            l1=CandidatesList['Motif'].iloc[i] #prima lista\n",
    "            l2=np.append(l2,l1[j][0]) #prendo primo valore di ogni lista\n",
    "            counterNumberMotif+=1\n",
    "            \n",
    "    \n",
    "        CandidatesList['Motif'].iloc[i]=l2\n",
    "        l2=np.array([]) #svuoto array\n",
    "    \n",
    "    return CandidatesList,counterNumberMotif,counterNumberDiscord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "def buildCandidatesUsedList(CandidatesList,numberOfMotif,numberOfDiscord):\n",
    "    CandidatesUsedList=pd.DataFrame(columns=['Used'],index=range(0,numberOfMotif+numberOfDiscord))\n",
    "    boolList=[False] * (numberOfMotif+numberOfDiscord)\n",
    "    CandidatesUsedList['Used']= boolList\n",
    "    return CandidatesUsedList\n",
    "                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataStructures(df,window_size):\n",
    "    #trasformo da stringa a numero il campo target \n",
    "    le = LabelEncoder()\n",
    "    num_classes = le.fit_transform(df['target'])\n",
    "    df['target']=num_classes\n",
    "    df['TsIndex']=np.arange(len(df))\n",
    "    window_size=5\n",
    "    #diz={'Motif':[],'Motif-Dist':[],'Discord':[]}\n",
    "    diz={'Motif':[],'Discord':[]}\n",
    "\n",
    "    #CALCOLO MOTIF E DISCORD E LI INSERISCO NEL DIZIONARIO\n",
    "    for i in range(len(df)):\n",
    "        Ts = np.array(df.iloc[i][0:-2].values)\n",
    "        mp,mot,motif_dist,dis = retrieve_all(Ts,window_size)\n",
    "        diz['Motif'].insert(i, mot)\n",
    "        diz['Discord'].insert(i, dis)\n",
    "\n",
    "    #GENERO DFRAME DA DIZIONARIO\n",
    "\n",
    "    CandidatesList = pd.DataFrame(diz)\n",
    "    CandidatesList,numberOfMotif,numberOfDiscord=candidateFilter(CandidatesList)\n",
    "    CandidatesUsedList=buildCandidatesUsedList(CandidatesList,numberOfMotif,numberOfDiscord)\n",
    "\n",
    "    print('Candidati estratti')\n",
    "    #print(MotifsList['Motif'])\n",
    "    print(CandidatesList)\n",
    "    print(numberOfMotif,numberOfDiscord)\n",
    "    print(CandidatesUsedList)\n",
    "    \n",
    "    return mp,CandidatesList,numberOfMotif,numberOfDiscord,CandidatesUsedList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#per ogni Ts calcolo Dprofile con ogni candidato e inserisco la distanza minima con candidato i-esimo nella colonna i-esima\n",
    "def computeSubSeqDistance(dataset,CandidatesList):\n",
    "    \n",
    "    #quantifico il num di candidati e in base a tale valore genero colonne per dfForDTree\n",
    "    numberOfCandidates=0\n",
    "    for i in range(len(CandidatesList)):\n",
    "            numberOfCandidates+=len(CandidatesList['Motif'].loc[i])\n",
    "            numberOfCandidates+=len(CandidatesList['Discord'].loc[i])\n",
    "    columnsList=np.arange(numberOfCandidates)\n",
    "    columnsList2=list()\n",
    "    lastAttribute=['TsIndex','class']\n",
    "    prefix='cand'\n",
    "    for i in columnsList:\n",
    "        columnsList2.append(prefix+str(i)) \n",
    "    columnsList2.append('TsIndex')\n",
    "    columnsList2.append('class')\n",
    "    dfForDTree=pd.DataFrame(columns=columnsList2,index=range(0,len(dataset)))\n",
    "\n",
    "    #per ogni Ts, scandisco ogni candidato e calcolo la distanza minore \n",
    "    for i in range(len(dataset)):\n",
    "        #acquisisco la Ts\n",
    "        TsToCompare = np.array(dataset.iloc[i].values) \n",
    "        classValue=TsToCompare[128]\n",
    "        TsToCompare=TsToCompare[0:128]\n",
    "        dfForDTree['TsIndex'].iloc[i]=i\n",
    "        dfForDTree['class'].iloc[i]=classValue\n",
    "        counter=0\n",
    "        #scandisco e calcolo distanza dai motif\n",
    "        for j in range(len(CandidatesList)):\n",
    "            numMotif=len(CandidatesList['Motif'].iloc[j])\n",
    "            numDiscord=len(CandidatesList['Discord'].iloc[j])\n",
    "            for k in range(numMotif):\n",
    "                l1=CandidatesList['Motif'].iloc[j] #lista di indice i in motifDiscordList\n",
    "                startingIndex=l1[k] #indice di inizio del motif\n",
    "                TsContainingCandidateShapelet = np.array(dataset.iloc[j].values) #Ts contenente candidato shapelet\n",
    "                Dp=distanceProfile.massDistanceProfile(TsContainingCandidateShapelet,int(startingIndex),window_size,TsToCompare)\n",
    "                minValueFromDProfile=min(Dp[0]) #Dp[0] contiene il Dp effettivo\n",
    "                dfForDTree[prefix+str(counter)].iloc[i]=minValueFromDProfile\n",
    "                counter+=1\n",
    "            for k in range(numDiscord):\n",
    "                l1=CandidatesList['Discord'].iloc[j] #lista di indice i in motifDiscordList\n",
    "                startingIndex=l1[k] #indice di inizio del motif\n",
    "                TsContainingCandidateShapelet = np.array(dataset.iloc[j].values) #Ts contenente candidato shapelet\n",
    "                Dp=distanceProfile.massDistanceProfile(TsContainingCandidateShapelet,int(startingIndex),window_size,TsToCompare)\n",
    "                minValueFromDProfile=min(Dp[0]) #Dp[0] contiene il Dp effettivo\n",
    "                dfForDTree[prefix+str(counter)].iloc[i]=minValueFromDProfile\n",
    "                counter+=1\n",
    "        \n",
    "   # print(counter)    \n",
    "    return dfForDTree #columnsList2 restituito per generare poi dFrame in \"Split\" (struttura dframe)\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset (dframe): nella riga i: indice della ts di appartenenza, distanza tra candidato e Ts, e classe di appartenenza di Ts\n",
    "#calcola entropia di un dataset basandosi sul num di classi esistenti\n",
    "def computeEntropy(dataset):\n",
    "    value,counts = np.unique(dataset['class'], return_counts=True)\n",
    "    actualEntropy=entropy(counts, base=2)\n",
    "    return actualEntropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calcola il gain tra entropia nodo padre e sommatoria entropia nodi figli (GAIN CALCOLATO SUL VALORE DELL'ATTRIBUTO)\n",
    "def computeGain(entropyParent,LenDatasetParent,Dleft,Dright):\n",
    "    entropyLeft=computeEntropy(Dleft)\n",
    "    entropyRight=computeEntropy(Dright)\n",
    "    gain=entropyParent\n",
    "    summation=( ((len(Dleft)/LenDatasetParent)*entropyLeft) +  ((len(Dright)/LenDatasetParent)*entropyRight) )\n",
    "    #print('entropyParent: '+str(entropyParent))\n",
    "    #print('SUMMATION: '+str(summation))\n",
    "    gain=gain-summation\n",
    "    return gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLIT SLAVE\n",
    "#effettua lo split del dataset sul attributo e valore fornito\n",
    "def split(dataset,attribute,value): \n",
    "    columnsList=dataset.columns.values\n",
    "    dizLeft=pd.DataFrame(columns=columnsList)\n",
    "    dizRight=pd.DataFrame(columns=columnsList)\n",
    "    for i in range(len(dataset)):\n",
    "        if dataset.iloc[i][attribute] < value:\n",
    "            dizLeft = dizLeft.append(dataset.iloc[i], ignore_index=True)\n",
    "        else:\n",
    "            dizRight = dizRight.append(dataset.iloc[i], ignore_index=True)\n",
    "    return dizLeft, dizRight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "# riceve dframe con mutual_information(gain) e in base al candidatesGroup scelto, determina il miglior attributo su cui splittare\n",
    "# che non è stato ancora utilizzato\n",
    "def getBestIndexAttribute(vecMutualInfo,candidatesGroup,CandidatesUsedListTrain,numberOfMotif,numberOfDiscord):\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    #ordino i candidati in base a gain decrescente\n",
    "    \n",
    "    vecMutualInfo=vecMutualInfo.sort_values(by='gain',ascending = False)\n",
    "\n",
    "    \n",
    "    print('computeMutualInfo ha generato questo, dopo averlo ordinato')\n",
    "    print(vecMutualInfo)\n",
    "    \n",
    "    #scandisco i candidati fino a trovare il candidato con miglior gain che non è ancora stato usato\n",
    "    \n",
    "    bestIndexAttribute=-1\n",
    "    i=0\n",
    "    \n",
    "    #cicla fin quando trova candidato libero con gain maggiore\n",
    "    while(bestIndexAttribute==-1 and i<len(vecMutualInfo)):    \n",
    "        attributeToVerify=int(vecMutualInfo.iloc[i]['attribute'])\n",
    "        if(CandidatesUsedListTrain.iloc[attributeToVerify]['Used']==False):\n",
    "            bestIndexAttribute=attributeToVerify\n",
    "            splitValue=vecMutualInfo.iloc[i]['splitValue']\n",
    "            CandidatesUsedListTrain.iloc[attributeToVerify]=True #settando a true il candidato scelto, non sarà usato in seguito\n",
    "        else:\n",
    "            i+=1\n",
    "    \n",
    "    return bestIndexAttribute,splitValue\n",
    "            \n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeMutualInfo(datasetForMutual,candidatesGroup,numberOfMotif,numberOfDiscord):\n",
    "    \n",
    "    #definisco struttura per memorizzare, dato un candidato(attributo), il valore su cui lo split massimizza il gain\n",
    "    if(candidatesGroup==0):\n",
    "        candidatesIndex=range(numberOfMotif)\n",
    "        numAttributes=numberOfMotif\n",
    "    elif(candidatesGroup==1):\n",
    "        candidatesIndex=range(numberOfMotif,numberOfMotif+numberOfDiscord)\n",
    "        numAttributes=numberOfDiscord\n",
    "    else:\n",
    "        candidatesIndex=range(numberOfMotif+numberOfDiscord)\n",
    "        numAttributes=numberOfMotif+numberOfDiscord\n",
    "    \n",
    "    \n",
    "    dframe=pd.DataFrame(columns=['attribute','splitValue','gain'],index=range(numAttributes))\n",
    "    entropyParent=computeEntropy(datasetForMutual)\n",
    "\n",
    "    \n",
    "    columns=datasetForMutual.columns\n",
    "    y=datasetForMutual['class']\n",
    "    \n",
    "    #per ogni attributo, ordino il dframe sul suo valore\n",
    "    #scandisco poi la y e appena cambia il valore di class effettuo uno split, memorizzando il best gain\n",
    "    \n",
    "    for i in range(len(columns)-1):\n",
    "        bestGain=-1\n",
    "        bestvalueForSplit=0\n",
    "        previousClass=-1 #deve essere settato ad un valore non presente nei class value\n",
    "        attribute=columns[i]\n",
    "        datasetForMutual=datasetForMutual.sort_values(by=attribute,ascending = True)    \n",
    "        \n",
    "       \n",
    "        \n",
    "        for j in range(len(y)):\n",
    "            if(j==0):\n",
    "                previousClass=y[j]\n",
    "                continue\n",
    "            else:\n",
    "                if(y[j]!=previousClass):\n",
    "                    testValue=datasetForMutual.iloc[j][attribute]\n",
    "                    Dleft,Dright=split(datasetForMutual,attribute,testValue)\n",
    "                    actualGain=computeGain(entropyParent,len(datasetForMutual),Dleft,Dright)\n",
    "                    if(actualGain > bestGain):\n",
    "                        bestGain=actualGain\n",
    "                        bestvalueForSplit=testValue\n",
    "               \n",
    "                previousClass=y[j] \n",
    "        # memorizzo in posizione i-esima lo split migliore e relativo gain\n",
    "        \n",
    "        dframe.iloc[i]['splitValue']=bestvalueForSplit\n",
    "        dframe.iloc[i]['gain']=bestGain\n",
    "        \n",
    "    \n",
    "    dframe['attribute']=candidatesIndex\n",
    "    return dframe\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLIT INTERMEDIO\n",
    "#dato il dataset, cerca il miglior attributo e relativo valore (optimal split point) su cui splittare\n",
    "# restituiendo il dataset splittato e i valori trovati\n",
    "def findBestAttributeValue(dataset,candidatesGroup,CandidatesUsedListTrain,numberOfMotif,numberOfDiscord,removeUsedCandidate):\n",
    "    #cerca e restituisce attributo migliore su cui splittaree relativo valore ottimale (optimal split point)\n",
    "    #CANDIDATE GROUP permette di scegliere se usare come candidati 0=motifs 1=discord 2=entrambi\n",
    "    bestGain=0\n",
    "    actualGain=0\n",
    "    bestvalueForSplit=0\n",
    "    y = dataset['class'].values\n",
    "    y=y.astype('int')\n",
    "    entropyParent=computeEntropy(dataset)\n",
    "    \n",
    "    #trovo best Attribute\n",
    "    numAttributes=len(dataset.columns.values)\n",
    "    numAttributes-=2 #tolgo i due attributi TsIndex e class dal Dframe\n",
    "    datasetForMutual=pd.DataFrame()\n",
    "    \n",
    "    #preparo il Dframe da passare a mutual_info_classif, settando se scegliere tra motifs/discord/entrambi\n",
    "    \n",
    "    if(candidatesGroup==0): #solo motifs\n",
    "        dataset=dataset.iloc[:,np.r_[:numberOfMotif]]\n",
    "    elif(candidatesGroup==1):\n",
    "        datasetForMutual=dataset.iloc[:,np.r_[numberOfMotif:numberOfMotif+numberOfDiscord]]\n",
    "    else:\n",
    "        datasetForMutual=dataset.iloc[:,np.r_[:numAttributes]]\n",
    "\n",
    "        \n",
    "    datasetForMutual['class']=y\n",
    "    \n",
    "    vecMutualInfo=computeMutualInfo(datasetForMutual,candidatesGroup,numberOfMotif,numberOfDiscord)\n",
    "    \n",
    "    print(vecMutualInfo)\n",
    "    \n",
    "    \n",
    "    if(removeUsedCandidate==1): \n",
    "        indexBestAttribute,bestValueForSplit=getBestIndexAttribute(vecMutualInfo,candidatesGroup,CandidatesUsedListTrain,numberOfMotif,numberOfDiscord)\n",
    "    else: #se non rimuovo candidati, mi basta prendere il primo\n",
    "        vecMutualInfo=vecMutualInfo.sort_values(by='gain',ascending = False)\n",
    "        indexBestAttribute=vecMutualInfo.iloc[0]['attribute']\n",
    "        bestValueForSplit=vecMutualInfo.iloc[0]['splitValue']\n",
    "        \n",
    "    \n",
    "    print('indici: ')\n",
    "    print(indexBestAttribute,bestValueForSplit)\n",
    "    \n",
    "    \n",
    "    \n",
    "    Dleft,Dright=split(dataset,indexBestAttribute,bestValueForSplit)\n",
    "    \n",
    "    \n",
    "    return indexBestAttribute,bestvalueForSplit,Dleft,Dright\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLIT MASTER\n",
    "# funzione ricorsiva che implementa la creazione dell'albero di classificazione\n",
    "# memorizza in ogni nodo: attributo, valore attributo su cui splitto, entropia nodo, num pattern\n",
    "# memorizza in ogni foglia: entropia nodo, num pattern, classe nodo\n",
    "\n",
    "# VERSIONE CHE RIMUOVE I CANDIDATI QUANDO VENGONO SCELTI \n",
    "\n",
    "def buildTree(actualNode,dataset,maxDepth, minSamplesLeaf, depth,candidatesGroup,CandidatesUsedListTrain,numberOfMotif,numberOfDiscord,removeUsedCandidate):\n",
    "    #caso base: num pattern < soglia minima || profondità massima raggiunta => genero foglia con media delle classi\n",
    "    #DATASET HA SEMPRE ALMENO UN PATTERN\n",
    "    boolValue=checkIfIsLeaf(dataset)\n",
    "    if(len(dataset)<minSamplesLeaf or depth>=maxDepth or boolValue==True ):\n",
    "        average = sum(dataset['class'].values) / len(dataset['class'].values)\n",
    "        classValue = round(average)\n",
    "        numPattern=len(dataset)\n",
    "        entropy=computeEntropy(dataset)\n",
    "        \n",
    "        nodeInfo=list()\n",
    "        nodeInfo.append(classValue)\n",
    "        nodeInfo.append(numPattern)\n",
    "        nodeInfo.append(entropy)\n",
    "    \n",
    "        actualNode.data=nodeInfo\n",
    "        actualNode.value=-1\n",
    "        actualNode.left=None\n",
    "        actualNode.right=None\n",
    "        #print(dataset['class'])\n",
    "        return \n",
    "    #caso ricorsivo in cui si può splittare\n",
    "    else:\n",
    "        \n",
    "        indexChosenAttribute,attributeValue,Dleft,Dright=findBestAttributeValue(dataset,candidatesGroup,CandidatesUsedListTrain,numberOfMotif,numberOfDiscord,removeUsedCandidate)\n",
    "        numPattern=len(dataset)\n",
    "        entropy=computeEntropy(dataset)\n",
    "        attributeList.append(indexChosenAttribute)\n",
    "        \n",
    "        #memorizzo nel nodo l'attributo, il valore e altre info ottenute dallo split\n",
    "        \n",
    "        nodeInfo=list()\n",
    "        nodeInfo.append(attributeValue)\n",
    "        nodeInfo.append(numPattern)\n",
    "        nodeInfo.append(entropy)\n",
    "        actualNode.data=nodeInfo\n",
    "        actualNode.value=(indexChosenAttribute)\n",
    "        \n",
    "        #se possibile richiamo ricorsivamente sul nodo dx e sx figlio\n",
    "        if(len(Dleft)>0):\n",
    "            actualNode.left=Node(indexChosenAttribute)\n",
    "            buildTree(actualNode.left,Dleft,maxDepth, minSamplesLeaf, depth+1,candidatesGroup,CandidatesUsedListTrain,numberOfMotif,numberOfDiscord,removeUsedCandidate)\n",
    "        \n",
    "        if(len(Dright)>0):\n",
    "            actualNode.right=Node(indexChosenAttribute)\n",
    "            buildTree(actualNode.right,Dright,maxDepth, minSamplesLeaf, depth+1,candidatesGroup,CandidatesUsedListTrain,numberOfMotif,numberOfDiscord,removeUsedCandidate)\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verifica se dataset, ha pattern appartenenti ad una sola classe => è gia foglia\n",
    "def checkIfIsLeaf(dataset):\n",
    "    isLeaf=True\n",
    "    entropy=computeEntropy(dataset)\n",
    "    if(entropy>0):\n",
    "        isLeaf=False\n",
    "    return isLeaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "#effettua il primo passo dell'algo di generazione dell'albero, richiama ricorsivamente sui figli\n",
    "# VERSIONE CHE NON RIMUOVE I CANDIDATI QUANDO VENGONO SCELTI \n",
    "def startAlgo(dfForDTree,candidatesGroup,CandidatesUsedListTrain,maxDepth,minSamplesLeaf,numberOfMotif,numberOfDiscord,removeUsedCandidate):\n",
    "    \n",
    "    #inizio algo per nodo radice\n",
    "    indexChosenAttribute,attributeValue,Dleft,Dright=findBestAttributeValue(dfForDTree,candidatesGroup,CandidatesUsedListTrain,numberOfMotif,numberOfDiscord,removeUsedCandidate)\n",
    "    attributeList.append(indexChosenAttribute)\n",
    "    root=Node(indexChosenAttribute)\n",
    "    numPattern=len(dfForDTree)\n",
    "    entropy=computeEntropy(dfForDTree)\n",
    "        \n",
    "    #memorizzo nel nodo l'attributo, il valore e altre info ottenute dallo split\n",
    "        \n",
    "    nodeInfo=list()\n",
    "    nodeInfo.append(attributeValue)\n",
    "    nodeInfo.append(numPattern)\n",
    "    nodeInfo.append(entropy)\n",
    "    root.data=nodeInfo\n",
    "    \n",
    "    root.left=Node(indexChosenAttribute)\n",
    "    root.right=Node(indexChosenAttribute)\n",
    "    \n",
    "    #chiamata ricorsiva\n",
    "    if(len(Dleft)>0):\n",
    "        buildTree(root.left,Dleft,maxDepth, minSamplesLeaf,1,candidatesGroup,CandidatesUsedListTrain,numberOfMotif,numberOfDiscord,removeUsedCandidate)\n",
    "    if(len(Dright)>0):\n",
    "        buildTree(root.right,Dright,maxDepth, minSamplesLeaf, 1,candidatesGroup,CandidatesUsedListTrain,numberOfMotif,numberOfDiscord,removeUsedCandidate)\n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stampa dell'albero\n",
    "def printAll(Root):\n",
    "    if(Root.left==None and Root.right==None):\n",
    "        print('foglia')\n",
    "    print('Nodo: '+str(Root.value))\n",
    "    df=Root.data\n",
    "    print(df)\n",
    "    print(\"\\n\")\n",
    "    if(Root.left!=None):\n",
    "        printAll(Root.left)\n",
    "    if(Root.right!=None):\n",
    "        printAll(Root.right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(testDataset,root):\n",
    "    print('START PRED')\n",
    "    #preparo dataset \n",
    "    numAttributes=len(testDataset.columns.values)\n",
    "    numAttributes-=2 #per prendere solo gli attributi utili a xTest\n",
    "    yTest=testDataset.iloc[:]['class'].values\n",
    "    yPredicted=np.zeros( len(yTest) )\n",
    "    xTest=testDataset.iloc[:,np.r_[:numAttributes]]\n",
    "    \n",
    "    #effettuo predizione per ogni pattern\n",
    "    \n",
    "    for i in range(len(xTest)):\n",
    "        pattern=xTest.iloc[i]\n",
    "        yPredicted[i]= treeExplorer(pattern,root)\n",
    "    \n",
    "    yTest = yTest.astype(int)\n",
    "    yPredicted = yPredicted.astype(int)\n",
    "    \n",
    "    return yTest,yPredicted\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treeExplorer(pattern,node):\n",
    "    #caso base, node è foglia\n",
    "    if(node.value==-1):\n",
    "        return int(node.data[0])\n",
    "    else:\n",
    "    #caso ricorsivo\n",
    "        attr='cand'+str(node.value)\n",
    "        if(pattern[attr] < node.data[0]):\n",
    "            print('left')\n",
    "            return treeExplorer(pattern,node.left)\n",
    "        else:\n",
    "            print('right')\n",
    "            return treeExplorer(pattern,node.right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeSubSeqDistanceForTest(datasetTest,datasetTrain,attributeList,CandidatesList,numberOfMotif,numberOfDiscord):\n",
    "    #quantifico il num di candidati usati dall'albero e in base a tale valore genero colonne per dfForDTree\n",
    "      #quantifico il num di candidati e in base a tale valore genero colonne per dfForDTree\n",
    "    columnsList2=list()\n",
    "    prefix='cand'\n",
    "    for i in attributeList:\n",
    "        columnsList2.append(prefix+str(i)) \n",
    "    columnsList2.append('TsIndex')\n",
    "    columnsList2.append('class')\n",
    "    dfForDTree=pd.DataFrame(columns=columnsList2,index=range(0,len(datasetTest)))\n",
    "\n",
    "    #per ogni Ts, scandisco ogni candidato e calcolo la distanza minore \n",
    "    for i in range(len(datasetTest)):\n",
    "        #acquisisco la Ts\n",
    "        TsToCompare = np.array(datasetTest.iloc[i].values) \n",
    "        classValue=TsToCompare[128]\n",
    "        TsToCompare=TsToCompare[0:128]\n",
    "        dfForDTree['TsIndex'].iloc[i]=i\n",
    "        dfForDTree['class'].iloc[i]=classValue\n",
    "        counter=0\n",
    "        #scandisco e calcolo distanza dai motif\n",
    "        for z in range(len(attributeList)):\n",
    "            candidateIndex=attributeList[z]\n",
    "            counter=0\n",
    "            for j in range(len(CandidatesList)):\n",
    "                numMotif=len(CandidatesList['Motif'].iloc[j])\n",
    "                numDiscord=len(CandidatesList['Discord'].iloc[j])\n",
    "                for k in range(numMotif):\n",
    "                    if(counter==candidateIndex):\n",
    "                        l1=CandidatesList['Motif'].iloc[j] #lista di indice i in motifDiscordList\n",
    "                        startingIndex=l1[k] #indice di inizio del motif\n",
    "                        TsContainingCandidateShapelet = np.array(datasetTrain.iloc[j].values) #Ts contenente candidato shapelet\n",
    "                        Dp=distanceProfile.massDistanceProfile(TsContainingCandidateShapelet,int(startingIndex),window_size,TsToCompare)\n",
    "                        minValueFromDProfile=min(Dp[0]) #Dp[0] contiene il Dp effettivo\n",
    "                        print(counter,candidateIndex,minValueFromDProfile)\n",
    "                        dfForDTree[prefix+str(counter)].iloc[i]=minValueFromDProfile\n",
    "                    counter+=1\n",
    "                        \n",
    "                for k in range(numDiscord):\n",
    "                    if(counter==candidateIndex):\n",
    "                        print(counter,candidateIndex)\n",
    "                        l1=CandidatesList['Discord'].iloc[j] #lista di indice i in motifDiscordList\n",
    "                        startingIndex=l1[k] #indice di inizio del motif\n",
    "                        TsContainingCandidateShapelet = np.array(datasetTrain.iloc[j].values) #Ts contenente candidato shapelet\n",
    "                        Dp=distanceProfile.massDistanceProfile(TsContainingCandidateShapelet,int(startingIndex),window_size,TsToCompare)\n",
    "                        minValueFromDProfile=min(Dp[0]) #Dp[0] contiene il Dp effettivo\n",
    "                        print(counter,candidateIndex,minValueFromDProfile)\n",
    "                        dfForDTree[prefix+str(counter)].iloc[i]=minValueFromDProfile\n",
    "                    counter+=1\n",
    "                    \n",
    "\n",
    "\n",
    "\n",
    "    le = LabelEncoder()        \n",
    "    num_classes = le.fit_transform(dfForDTree['class'])\n",
    "    dfForDTree['class']=num_classes\n",
    "            \n",
    "    return dfForDTree #columnsList2 restituito per generare poi dFrame in \"Split\" (struttura dframe)\n",
    "                \n",
    "    \n",
    "    #print(CandidatesList)\n",
    "    #print(attributeDF)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidati estratti\n",
      "            Motif    Discord\n",
      "0     [9.0, 26.0]   [61, 27]\n",
      "1   [105.0, 54.0]   [8, 119]\n",
      "2    [17.0, 40.0]    [31, 1]\n",
      "3    [48.0, 12.0]   [23, 86]\n",
      "4          [27.0]   [38, 62]\n",
      "5    [45.0, 13.0]  [119, 26]\n",
      "6     [7.0, 37.0]   [98, 76]\n",
      "7     [2.0, 24.0]    [36, 8]\n",
      "8     [1.0, 29.0]   [23, 32]\n",
      "9     [50.0, 0.0]   [38, 59]\n",
      "10   [11.0, 17.0]   [80, 23]\n",
      "11    [31.0, 7.0]  [114, 54]\n",
      "12         [53.0]   [61, 10]\n",
      "13    [79.0, 6.0]  [105, 38]\n",
      "14         [59.0]    [98, 8]\n",
      "15    [2.0, 45.0]     [1, 8]\n",
      "16    [28.0, 3.0]    [5, 88]\n",
      "17   [14.0, 35.0]  [118, 85]\n",
      "18    [13.0, 3.0]   [111, 8]\n",
      "19    [19.0, 6.0]   [92, 35]\n",
      "20   [19.0, 39.0]   [26, 70]\n",
      "21         [26.0]   [13, 35]\n",
      "22   [18.0, 22.0]   [59, 25]\n",
      "23   [27.0, 42.0]  [32, 104]\n",
      "24    [8.0, 28.0]    [4, 95]\n",
      "25         [16.0]   [87, 20]\n",
      "26   [67.0, 59.0]   [33, 83]\n",
      "27   [16.0, 39.0]   [75, 99]\n",
      "28   [11.0, 41.0]   [47, 39]\n",
      "29    [6.0, 15.0]  [117, 51]\n",
      "55 60\n",
      "      Used\n",
      "0    False\n",
      "1    False\n",
      "2    False\n",
      "3    False\n",
      "4    False\n",
      "..     ...\n",
      "110  False\n",
      "111  False\n",
      "112  False\n",
      "113  False\n",
      "114  False\n",
      "\n",
      "[115 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "#ACQUISISCO STRUTTURE DATI DEL TRAINING SET\n",
    "dataset = arff.loadarff('CBF/CBF_TRAIN.arff')\n",
    "dfTrain=pd.DataFrame(dataset[0])\n",
    "window_size=5\n",
    "mpTrain,CandidatesListTrain,numberOfMotifTrain,numberOfDiscordTrain,CandidatesUsedListTrain=getDataStructures(dfTrain,window_size)\n",
    "dfForDTree=computeSubSeqDistance(dfTrain,CandidatesListTrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-308-10a68daf5120>:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  datasetForMutual['class']=y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    attribute splitValue      gain\n",
      "0          55    0.98486  0.721928\n",
      "1          56   0.691605  0.334498\n",
      "2          57   0.871049  0.485475\n",
      "3          58   0.644435  0.395816\n",
      "4          59   0.828827  0.246439\n",
      "5          60    0.68825  0.268996\n",
      "6          61   0.833422  0.334498\n",
      "7          62   0.920286  0.520327\n",
      "8          63   0.644171  0.485475\n",
      "9          64   0.840668  0.244838\n",
      "10         65   0.952141  0.520327\n",
      "11         66   0.705466  0.209987\n",
      "12         67   0.526289  0.195816\n",
      "13         68   0.809785  0.209987\n",
      "14         69   0.917434  0.605802\n",
      "15         70   0.639301  0.334498\n",
      "16         71   0.617034  0.285475\n",
      "17         72   0.882275  0.236453\n",
      "18         73   0.759134  0.334498\n",
      "19         74   0.984968  0.246439\n",
      "20         75   0.630125  0.520327\n",
      "21         76   0.621935  0.605802\n",
      "22         77   0.616463  0.209987\n",
      "23         78   0.852417  0.770951\n",
      "24         79    1.14742  0.268996\n",
      "25         80   0.979038  0.246439\n",
      "26         81   0.666132  0.485475\n",
      "27         82    1.05697  0.193507\n",
      "28         83    1.24014  0.108032\n",
      "29         84   0.791777  0.695462\n",
      "30         85   0.749185  0.285475\n",
      "31         86    0.69527  0.605802\n",
      "32         87   0.608308  0.520327\n",
      "33         88   0.415046  0.520327\n",
      "34         89   0.607557  0.520327\n",
      "35         90   0.831339  0.395816\n",
      "36         91   0.704653  0.285475\n",
      "37         92   0.623692  0.609987\n",
      "38         93   0.582001  0.209987\n",
      "39         94    1.03262  0.268996\n",
      "40         95   0.903295  0.244838\n",
      "41         96   0.518384  0.244838\n",
      "42         97    0.80363  0.209987\n",
      "43         98   0.673392  0.209987\n",
      "44         99    1.07115  0.268996\n",
      "45        100   0.842711  0.236453\n",
      "46        101    0.79734  0.285475\n",
      "47        102    0.53142  0.485475\n",
      "48        103   0.364709  0.395816\n",
      "49        104   0.599091  0.209987\n",
      "50        105   0.932763  0.236453\n",
      "51        106   0.545163  0.244838\n",
      "52        107   0.756261  0.520327\n",
      "53        108   0.727362  0.405802\n",
      "54        109   0.818844  0.770951\n",
      "55        110   0.656383  0.285475\n",
      "56        111    1.20192  0.268996\n",
      "57        112   0.787542  0.209987\n",
      "58        113   0.928936  0.209987\n",
      "59        114   0.667375  0.334498\n",
      "indici: \n",
      "78 0.8524166491790355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-308-10a68daf5120>:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  datasetForMutual['class']=y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    attribute splitValue      gain\n",
      "0          55   0.859166  0.316689\n",
      "1          56   0.691605  0.316689\n",
      "2          57   0.871049  0.190875\n",
      "3          58    0.65421  0.190875\n",
      "4          59   0.718226  0.190875\n",
      "5          60   0.556222  0.190875\n",
      "6          61    0.93276  0.316689\n",
      "7          62   0.920286  0.316689\n",
      "8          63   0.770227  0.190875\n",
      "9          64   0.671732  0.190875\n",
      "10         65   0.952141  0.316689\n",
      "11         66   0.705466  0.190875\n",
      "12         67   0.859219  0.190875\n",
      "13         68   0.809785  0.190875\n",
      "14         69   0.815703  0.316689\n",
      "15         70   0.806636  0.190875\n",
      "16         71   0.740667  0.316689\n",
      "17         72   0.808822  0.190875\n",
      "18         73   0.759134  0.316689\n",
      "19         74   0.911995  0.316689\n",
      "20         75   0.630125  0.316689\n",
      "21         76   0.797819  0.190875\n",
      "22         77   0.628522  0.190875\n",
      "23         78   0.732693  0.316689\n",
      "24         79   0.615266  0.190875\n",
      "25         80   0.787926  0.190875\n",
      "26         81    0.72411  0.190875\n",
      "27         82   0.747722  0.190875\n",
      "28         83   0.660129  0.190875\n",
      "29         84   0.847349  0.190875\n",
      "30         85   0.749185  0.190875\n",
      "31         86   0.669986  0.316689\n",
      "32         87   0.716008  0.190875\n",
      "33         88    0.48631  0.190875\n",
      "34         89   0.635321  0.190875\n",
      "35         90   0.831339  0.190875\n",
      "36         91   0.704653  0.190875\n",
      "37         92   0.936626  0.190875\n",
      "38         93   0.649282  0.190875\n",
      "39         94   0.838451  0.316689\n",
      "40         95   0.548554  0.190875\n",
      "41         96   0.666467  0.190875\n",
      "42         97    0.80363  0.190875\n",
      "43         98   0.673392  0.190875\n",
      "44         99   0.843951  0.316689\n",
      "45        100   0.586944  0.190875\n",
      "46        101    0.79734  0.190875\n",
      "47        102   0.909925  0.190875\n",
      "48        103   0.404467  0.190875\n",
      "49        104   0.599091  0.190875\n",
      "50        105   0.728336  0.190875\n",
      "51        106   0.811727  0.190875\n",
      "52        107   0.756261  0.316689\n",
      "53        108   0.846643  0.190875\n",
      "54        109   0.526756  0.190875\n",
      "55        110   0.656383  0.190875\n",
      "56        111   0.824953  0.316689\n",
      "57        112   0.787542  0.190875\n",
      "58        113   0.928936  0.190875\n",
      "59        114   0.667375  0.316689\n",
      "indici: \n",
      "55 0.8591663543330765\n",
      "\n",
      "     ____78\n",
      "    /      \\\n",
      "  _55       -1\n",
      " /   \\\n",
      "-1    -1\n",
      "\n",
      "[78, 55]\n",
      "Nodo: 78\n",
      "[0, 10, 1.4854752972273346]\n",
      "\n",
      "\n",
      "Nodo: 55\n",
      "[0, 6, 0.6500224216483541]\n",
      "\n",
      "\n",
      "foglia\n",
      "Nodo: -1\n",
      "[0.0, 4, 0.0]\n",
      "\n",
      "\n",
      "foglia\n",
      "Nodo: -1\n",
      "[1.0, 2, 1.0]\n",
      "\n",
      "\n",
      "foglia\n",
      "Nodo: -1\n",
      "[1.0, 4, 0.8112781244591328]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#COSTRUISCO DECISION TREE\n",
    "candidatesGroup=1\n",
    "albero=None\n",
    "maxDepth=3\n",
    "minSamplesLeaf=5\n",
    "attributeList=list()\n",
    "removeUsedCandidate=0\n",
    "albero=startAlgo(dfForDTree[:10],candidatesGroup,CandidatesUsedListTrain,maxDepth,minSamplesLeaf,numberOfMotifTrain,numberOfDiscordTrain,removeUsedCandidate)\n",
    "print(albero)\n",
    "print(attributeList)\n",
    "printAll(albero)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index out of bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\softwaretesi1\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_value\u001b[1;34m(self, series, key)\u001b[0m\n\u001b[0;32m   4404\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4405\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"tz\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4406\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 78",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-322-39106701b9bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdfForDTreeTest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m78\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.852417\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-19-d56373bb9d90>\u001b[0m in \u001b[0;36msplit\u001b[1;34m(dataset, attribute, value)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mdizRight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumnsList\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mattribute\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m             \u001b[0mdizLeft\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdizLeft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\softwaretesi1\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    869\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 871\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    872\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\softwaretesi1\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_value\u001b[1;34m(self, series, key)\u001b[0m\n\u001b[0;32m   4409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4410\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4411\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mlibindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value_at\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4412\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4413\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.get_value_at\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.get_value_at\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\util.pxd\u001b[0m in \u001b[0;36mpandas._libs.util.get_value_at\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\util.pxd\u001b[0m in \u001b[0;36mpandas._libs.util.validate_indexer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index out of bounds"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55 55\n",
      "55 55 0.38085105091467\n",
      "78 78 0.46926418239385115\n",
      "55 55\n",
      "55 55 0.7552626698407835\n",
      "78 78 0.29543429387540504\n",
      "55 55\n",
      "55 55 0.5703132735165596\n",
      "78 78 0.34482007571546275\n",
      "55 55\n",
      "55 55 0.480689235833118\n",
      "78 78 0.33733731487590585\n",
      "55 55\n",
      "55 55 0.2848619104323644\n",
      "78 78 0.7515832470598217\n",
      "55 55\n",
      "55 55 0.42687875794667796\n",
      "78 78 0.994886316999715\n",
      "55 55\n",
      "55 55 0.8901406658791136\n",
      "78 78 0.9458805456414962\n",
      "55 55\n",
      "55 55 0.5014299322194026\n",
      "78 78 0.8452146534581374\n",
      "55 55\n",
      "55 55 0.7004079385816188\n",
      "78 78 0.6464803937362571\n",
      "55 55\n",
      "55 55 0.5238560542789384\n",
      "78 78 1.1802681712761507\n",
      "55 55\n",
      "55 55 0.29814008006100573\n",
      "78 78 0.35444650899857416\n",
      "55 55\n",
      "55 55 0.4021089694648075\n",
      "78 78 0.7170214648057108\n",
      "55 55\n",
      "55 55 0.24812905659828938\n",
      "78 78 0.9321874362525677\n",
      "55 55\n",
      "55 55 0.9739732580676278\n",
      "78 78 0.45554276224811524\n",
      "55 55\n",
      "55 55 0.8523585353437044\n",
      "78 78 0.7436537696614453\n",
      "55 55\n",
      "55 55 0.5846335295961591\n",
      "78 78 0.5012213660804549\n",
      "55 55\n",
      "55 55 0.6967914150742313\n",
      "78 78 0.34211190777629163\n",
      "55 55\n",
      "55 55 0.6024165964561996\n",
      "78 78 0.3132479020218966\n",
      "55 55\n",
      "55 55 0.6331410638745272\n",
      "78 78 0.20047761572002243\n",
      "55 55\n",
      "55 55 0.6058827003321189\n",
      "78 78 0.45129517269187097\n",
      "55 55\n",
      "55 55 0.6782958698164322\n",
      "78 78 0.790587620788162\n",
      "55 55\n",
      "55 55 0.848510238998428\n",
      "78 78 0.8650466583228018\n",
      "55 55\n",
      "55 55 0.5191616266857478\n",
      "78 78 1.4910712648408044\n",
      "55 55\n",
      "55 55 0.7495686342368977\n",
      "78 78 0.6030531556799668\n",
      "55 55\n",
      "55 55 0.7916044155253121\n",
      "78 78 0.48900248160814547\n",
      "55 55\n",
      "55 55 0.8470741499832437\n",
      "78 78 0.8864135264397056\n",
      "55 55\n",
      "55 55 0.6925995214558207\n",
      "78 78 0.7594456391102626\n",
      "55 55\n",
      "55 55 0.9701736102929502\n",
      "78 78 0.2994383231207045\n",
      "55 55\n",
      "55 55 0.5210890618282368\n",
      "78 78 0.7758898253529917\n",
      "55 55\n",
      "55 55 0.9895553952400203\n",
      "78 78 0.3251919113278881\n",
      "55 55\n",
      "55 55 0.6066709050302155\n",
      "78 78 0.42258859276934635\n",
      "55 55\n",
      "55 55 0.8394118067163386\n",
      "78 78 0.5205489405250255\n",
      "55 55\n",
      "55 55 1.0305256694588978\n",
      "78 78 1.1557969094364977\n",
      "55 55\n",
      "55 55 0.7489281976089343\n",
      "78 78 0.5546364741186557\n",
      "55 55\n",
      "55 55 0.49592658449664956\n",
      "78 78 1.01562811850107\n",
      "55 55\n",
      "55 55 1.103272677728966\n",
      "78 78 0.21118464897464162\n",
      "55 55\n",
      "55 55 0.4861880658304634\n",
      "78 78 0.9141797015074737\n",
      "55 55\n",
      "55 55 0.6349051912598226\n",
      "78 78 0.3218632998175364\n",
      "55 55\n",
      "55 55 0.6941529115760313\n",
      "78 78 0.7333964286396087\n",
      "55 55\n",
      "55 55 0.70295827461791\n",
      "78 78 0.48341976579706036\n",
      "55 55\n",
      "55 55 0.17480809779070292\n",
      "78 78 0.5145554122326992\n",
      "55 55\n",
      "55 55 0.9390383810281245\n",
      "78 78 0.9218933121307175\n",
      "55 55\n",
      "55 55 0.9909029222153359\n",
      "78 78 1.0218537167277055\n",
      "55 55\n",
      "55 55 0.685522272010968\n",
      "78 78 0.6958317892063755\n",
      "55 55\n",
      "55 55 0.5727226829739644\n",
      "78 78 0.8517540614739255\n",
      "55 55\n",
      "55 55 0.8172678248364034\n",
      "78 78 0.8072446756209698\n",
      "55 55\n",
      "55 55 0.5307942210399355\n",
      "78 78 0.4536816908795784\n",
      "55 55\n",
      "55 55 0.6794376618501428\n",
      "78 78 0.4939975349189563\n",
      "55 55\n",
      "55 55 0.4472015567373097\n",
      "78 78 0.7966558390340657\n",
      "55 55\n",
      "55 55 0.6710955185895157\n",
      "78 78 0.8865581847738451\n",
      "      cand55    cand78 TsIndex  class\n",
      "0   0.380851  0.469264       0      2\n",
      "1   0.755263  0.295434       1      0\n",
      "2   0.570313   0.34482       2      2\n",
      "3   0.480689  0.337337       3      0\n",
      "4   0.284862  0.751583       4      1\n",
      "5   0.426879  0.994886       5      0\n",
      "6   0.890141  0.945881       6      2\n",
      "7    0.50143  0.845215       7      2\n",
      "8   0.700408   0.64648       8      2\n",
      "9   0.523856   1.18027       9      2\n",
      "10   0.29814  0.354447      10      1\n",
      "11  0.402109  0.717021      11      0\n",
      "12  0.248129  0.932187      12      2\n",
      "13  0.973973  0.455543      13      0\n",
      "14  0.852359  0.743654      14      2\n",
      "15  0.584634  0.501221      15      0\n",
      "16  0.696791  0.342112      16      0\n",
      "17  0.602417  0.313248      17      2\n",
      "18  0.633141  0.200478      18      1\n",
      "19  0.605883  0.451295      19      0\n",
      "20  0.678296  0.790588      20      1\n",
      "21   0.84851  0.865047      21      2\n",
      "22  0.519162   1.49107      22      2\n",
      "23  0.749569  0.603053      23      0\n",
      "24  0.791604  0.489002      24      1\n",
      "25  0.847074  0.886414      25      1\n",
      "26    0.6926  0.759446      26      1\n",
      "27  0.970174  0.299438      27      1\n",
      "28  0.521089   0.77589      28      2\n",
      "29  0.989555  0.325192      29      1\n",
      "30  0.606671  0.422589      30      0\n",
      "31  0.839412  0.520549      31      0\n",
      "32   1.03053    1.1558      32      0\n",
      "33  0.748928  0.554636      33      0\n",
      "34  0.495927   1.01563      34      2\n",
      "35   1.10327  0.211185      35      2\n",
      "36  0.486188   0.91418      36      2\n",
      "37  0.634905  0.321863      37      0\n",
      "38  0.694153  0.733396      38      2\n",
      "39  0.702958   0.48342      39      0\n",
      "40  0.174808  0.514555      40      2\n",
      "41  0.939038  0.921893      41      0\n",
      "42  0.990903   1.02185      42      1\n",
      "43  0.685522  0.695832      43      1\n",
      "44  0.572723  0.851754      44      0\n",
      "45  0.817268  0.807245      45      1\n",
      "46  0.530794  0.453682      46      2\n",
      "47  0.679438  0.493998      47      2\n",
      "48  0.447202  0.796656      48      0\n",
      "49  0.671096  0.886558      49      2\n"
     ]
    }
   ],
   "source": [
    "#GENERO STRUTTURE DATI PER TEST SET\n",
    "dataset2 = arff.loadarff('CBF/CBF_TEST.arff')\n",
    "window_size=5\n",
    "dfTest = pd.DataFrame(dataset2[0]) #30 record su matrice da 128 attributi + 'b': classe appartenenza  \n",
    "dfTest=dfTest.iloc[50:100] #ne prendo 50 altrimenti impiega tempo troppo lungo, sono 900 record totali\n",
    "\n",
    "attributeList=sorted(attributeList)\n",
    "dfForDTreeTest=computeSubSeqDistanceForTest(dfTest,dfTrain,attributeList,CandidatesListTrain,numberOfMotifTrain,numberOfDiscordTrain) \n",
    "print(dfForDTreeTest)\n",
    "\n",
    "#CONTROLLA, DOVRRBBE ESSERE GIUSTO COSI, SE USO COMPUTE NORMALE CON dfTest SBAGLIO DATASET DI RIFERIMENTO \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START PRED\n",
      "right\n",
      "right\n",
      "right\n",
      "right\n",
      "right\n",
      "right\n",
      "right\n",
      "right\n",
      "right\n",
      "right\n",
      "right\n",
      "right\n",
      "right\n",
      "right\n",
      "right\n",
      "right\n",
      "right\n",
      "right\n",
      "right\n",
      "right\n",
      "right\n",
      "right\n",
      "right\n",
      "right\n",
      "right\n",
      "right\n",
      "right\n",
      "right\n",
      "right\n",
      "right\n",
      "right\n",
      "right\n",
      "right\n",
      "right\n",
      "right\n",
      "right\n",
      "right\n",
      "right\n",
      "right\n",
      "right\n",
      "right\n",
      "right\n",
      "right\n",
      "right\n",
      "right\n",
      "right\n",
      "right\n",
      "right\n",
      "right\n",
      "right\n",
      "2 1\n",
      "0 1\n",
      "2 1\n",
      "0 1\n",
      "1 1\n",
      "0 1\n",
      "2 1\n",
      "2 1\n",
      "2 1\n",
      "2 1\n",
      "1 1\n",
      "0 1\n",
      "2 1\n",
      "0 1\n",
      "2 1\n",
      "0 1\n",
      "0 1\n",
      "2 1\n",
      "1 1\n",
      "0 1\n",
      "1 1\n",
      "2 1\n",
      "2 1\n",
      "0 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "2 1\n",
      "1 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "2 1\n",
      "2 1\n",
      "2 1\n",
      "0 1\n",
      "2 1\n",
      "0 1\n",
      "2 1\n",
      "0 1\n",
      "1 1\n",
      "1 1\n",
      "0 1\n",
      "1 1\n",
      "2 1\n",
      "2 1\n",
      "0 1\n",
      "2 1\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        18\n",
      "           1       0.24      1.00      0.39        12\n",
      "           2       0.00      0.00      0.00        20\n",
      "\n",
      "    accuracy                           0.24        50\n",
      "   macro avg       0.08      0.33      0.13        50\n",
      "weighted avg       0.06      0.24      0.09        50\n",
      "\n",
      "Accuracy 0.24\n",
      "F1-score [0.         0.38709677 0.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Allen\\softwaretesi1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0, 18,  0],\n",
       "       [ 0, 12,  0],\n",
       "       [ 0, 20,  0]], dtype=int64)"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#EFFETTUO PREDIZIONE E MISURO RISULTATO\n",
    "\n",
    "yTest,yPredicted=predict(dfForDTreeTest,albero)\n",
    "\n",
    "\n",
    "\n",
    "for a,b in zip(yTest,yPredicted):\n",
    "    print(a,b)\n",
    "    \n",
    "print(type(yPredicted))\n",
    "print(type(yTest))\n",
    "    \n",
    "print(classification_report(yTest, yPredicted))\n",
    "print('Accuracy %s' % accuracy_score(yTest, yPredicted))\n",
    "print('F1-score %s' % f1_score(yTest, yPredicted, average=None))\n",
    "confusion_matrix(yTest, yPredicted)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
