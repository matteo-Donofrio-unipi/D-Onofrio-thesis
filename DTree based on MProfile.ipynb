import pandas as pd
import numpy as np
from matrixprofile import *
from matrixprofile.discords import discords
from matplotlib import pyplot as plt
from scipy.io import arff
from binarytree import Node
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score, f1_score, classification_report
import pydotplus
from IPython.display import Image
from pandas.plotting import scatter_matrix
from math import log, e

def retrieve_all(Ts): #fornita la Ts calcola e restituisce mp, motifs, motifs_distances e discords
    Ts=Ts[0:127] #rimuovo l'attributo "classe"

    dfMP = pd.DataFrame(Ts).astype(float) # genero Dframe per lavorarci su, DA CAPIRE PERCHE SERVE FLOAT
    mp, mpi = matrixProfile.stomp(dfMP[0].values,window_size) #OK STOMP

    #PREPARO TUPLA DA PASSARE ALLA FUN MOTIF (RICHIEDE TUPLA FATTA DA MP E MPI)
    tupla=mp,mpi

    mot, motif_dist  =motifs.motifs(dfMP[0].values,tupla,2)

    #CALCOLO MOTIFS
   # print('Motifs starting position: '+str(mot)+ ' Motifs values (min distances): '+str(motif_dist))
   # print(" ")

    #CALCOLO DISCORDS
    dis= discords(mp,window_size,2)
    #print('Discords starting position: '+str(dis))
    
    tupla=mp,mot,motif_dist,dis
    return tupla

#riceve la lista di coppie dei motifs per ogni record(Ts), e resittuisce lista di valori singoli

def motifsFilter(MotifsList): 
    l2=np.array([])
    for i in range (len(MotifsList['Motif'])): #per ogni entry (per ogni record)
        numMotif=len(MotifsList['Motif'].loc[i])
        #print(numMotif)
        for j in range (numMotif): # per ogni lista di motif
            l1=MotifsList['Motif'].loc[i] #prima lista
            l2=np.append(l2,l1[j][0]) #prendo primo valore di ogni lista 
    
        MotifsList['Motif'].loc[i]=l2
        l2=np.array([]) #svuoto array
    
    return MotifsList
    





#carico dataset in dataFrame
dataset = arff.loadarff('CBF/CBF_TRAIN.arff')
df = pd.DataFrame(dataset[0]) #30 record su matrice da 128 attributi + 'b': classe appartenenza  
#trasformo da stringa a numero il campo target 
le = LabelEncoder()
num_classes = le.fit_transform(df['target'])
df['target']=num_classes
df['TsIndex']=np.arange(len(df))

print(df)

window_size=5
#diz={'Motif':[],'Motif-Dist':[],'Discord':[]}
diz={'Motif':[]}

for i in range(30):
    Ts = np.array(df.iloc[i].values)
    mp,mot,motif_dist,dis = retrieve_all(Ts[0:128])
    diz['Motif'].insert(i, mot)


MotifsList = pd.DataFrame(diz)
print('Motif estratti')
print(MotifsList)

MotifsList=motifsFilter(MotifsList)
print(MotifsList['Motif'])
Ts = np.array(df.iloc[0].values)
print(Ts[9:(9+5)])
print(Ts[26:(26+5)])



#Fun MOTIFS Returns tuple (motifs, distances)
    #motifs: a list of lists of indexes representing the motif starting locations.
    #distances: list of minimum distances for each motif
#riceve la lista degli indici di partenza dei motif, e le Ts, per ognuno di essi(motifs) genera un DistanceProfile con ogni Ts
#e prende il valore(distanza) minore con tale Ts

def retrieveSubSequenceDist(df,MotifsList):
    diz={'Index':[],'TsIndex':[],'motifStartingIndex':[],'Used':[],'SubSequenceDistArray':[]}
    
    
    #dfSubSeqDist -> TsIndex= indice della Ts a cui appartiene il candidato shapelet
    
    #                motifStartingIndex= indice di posizione di partenza del candidato shapelet nella TS
    
    #                Used= se è gia stato usato o meno nel DTree
    
    #                SubSequenceDistArray= array 2D in cui ogni riga i ha 
    #                indice della Ts(dell'elenco nel df), la distanza minima tra il candidato e la Ts i-esima,la classe della Ts-iesima
    #                NB: SubSequenceDistArray viene usato nel DTREE, contenuti nei dataset che vengono splittati
    
    # NB: la coppia TsIndex e motifStartingIndex IDENTIFICANO UNIVOCAMENTE un candidato Shapelet
    # L'INDICE DELLA Ts SI RIFERISCE ALLA POSIZIONE CHE OCCUPA NELLA MOTIFS LIST               
    
    
    counter=0
    
    for i in range(len(MotifsList['Motif'])):
        numMotif=len(MotifsList['Motif'].loc[i]) #quanti starting index di motif ci sono in pos i
        for j in range (numMotif):
            l1=MotifsList['Motif'].loc[i] #lista di indice i in MotifsList
            startingIndex=l1[j] #indice di inizio del motif
            #print(startingIndex)
            TsContainingCandidateShapelet = np.array(df.iloc[i].values) #Ts contenente candidato shapelet
            minValueList = np.array([]) #array contenente le subSeqDist calcolate dalla data SubSeq con tutte le ts
            for k in range (len(df)):
                TsToCompare = np.array(df.iloc[k].values)
                class_value=TsToCompare[128]
                TsToCompare=TsToCompare[0:128]
                Dp=distanceProfile.massDistanceProfile(TsContainingCandidateShapelet,int(startingIndex),window_size,TsToCompare)
                minValueList=np.append(minValueList,min(Dp[0])) #Dp[0] contiene il Dp effettivo
                
            diz['Index'].insert(counter, counter)
            diz['TsIndex'].insert(counter, i)
            diz['motifStartingIndex'].insert(counter, startingIndex)
            diz['Used'].insert(counter, False)
            
            dizForSubSeqArray=pd.DataFrame()
            dizForSubSeqArray['TsIndex']=np.arange(len(df))
            dizForSubSeqArray['minValueList']=minValueList
            dizForSubSeqArray['class']=num_classes
            
            diz['SubSequenceDistArray'].insert(counter, dizForSubSeqArray)

            
            counter=counter+1
    
    dfSubSeqDist=pd.DataFrame(diz)
    return dfSubSeqDist

dfSubSeqDist=pd.DataFrame()
dfSubSeqDist=retrieveSubSequenceDist(df,MotifsList)
dfSubSeqDist.set_index('Index')


print('')

#for a,b,c in zip(dfSubSeqDist['SubSequenceDistArray'].iloc[0][0], dfSubSeqDist['SubSequenceDistArray'].iloc[0][1],dfSubSeqDist['SubSequenceDistArray'].iloc[0][2]):
#    print(a,b,c)
    
print(dfSubSeqDist['SubSequenceDistArray'].iloc[0])
print(type(dfSubSeqDist['SubSequenceDistArray'].iloc[0]))

#FIN QUI: PER OGNI MOTIF ESTRATTO (IDENTIFICATO UNIVOCAMENTE DALLA TS DI APPARTENZENZA E INDICE DI PARTENZA IN ESSA)
#         HO CALCOLATO UN DPROFILE CON OGNI TS, PRESO IL VALORE(DISTANZA) MINORE DA OGNI DPROFILE 
#         E COSTRUITO UN VETTORE CONTENENTE QUINDI LA MINIMA DISTANZA TRA UN MOTIF FISSATO E TUTTE LE TS (SubSequenceDistArray)
#         IN TALE ARRAY, ACCANTO AD OGNI MINIMA DISTANZA, SALVO ANCHE L'INDICE E LA CLASSE DELLA TS CON CUI è STATA CALCOLATA
#         TALE INFO SONO FONDAMENTALI NEL DTREE

#SUBSEQDISARRAY: [INDICE TS][VALORE MINIMO CALCOLATO][CLASSE TS]

#dataset(dframe)= dfSubSeqDist['SubSequenceDistArray'].iloc[i] cioe la lista di distanze minime tra candidato i-esimo e tutte le TS      
def split(dataset,value): 
    dizLeft=pd.DataFrame(columns=['TsIndex','minValueList','class'])
    dizRight=pd.DataFrame(columns=['TsIndex','minValueList','class'])
    index=0
    for i in range(len(dataset)):
        if dataset.iloc[i]['minValueList'] < value:
            #dizLeft.[index]=dataset.iloc[i] #in ogni split aggiungo la distanza tra candidato e Ts, e la classe della Ts
            dizLeft = dizLeft.append(dataset.iloc[i], ignore_index=True)
        else:
            dizRight = dizRight.append(dataset.iloc[i], ignore_index=True)
        index+=1
    return dizLeft, dizRight





#dataset (dframe): nella riga i: indice della ts di appartenenza, distanza tra candidato e Ts, e classe di appartenenza di Ts
#calcola entropia di un dataset basandosi sul num di classi esistenti
def computeEntropy(dataset, num_classes_unique):
    numPattern=len(dataset)
    print('numPattern: '+str(numPattern))
    relativeFrequencies=list()
    counter=0 #num pattern di ogni classe nel dataset
    #ottengo frequenze relative
    for i in (num_classes_unique):
        for j in range(numPattern):
            if(dataset.iloc[j]['class']==i):
                counter+=1
        relativeFrequencies.append(counter/numPattern)
        counter=0
    #calcolo entropia dataset
    print('relativeFrequencies: '+str(relativeFrequencies))
    entropy=(relativeFrequencies[0]*log(relativeFrequencies[0],2))
    for k in (relativeFrequencies[1:]):
        if(k!=0):
            entropy+=(k*log(k,2))
    return -entropy
    
    

#calcola il gain tra entropia nodo padre e sommatoria entropia nodi figli
def computeGain(DatasetParent,Dleft,Dright,num_classes_unique):
    entropyParent=computeEntropy(DatasetParent,num_classes_unique)
    entropyLeft=computeEntropy(Dleft,num_classes_unique)
    entropyRight=computeEntropy(Dright,num_classes_unique)
    gain=entropyParent
    summation=( ((len(Dleft)/len(DatasetParent))*entropyLeft) +  ((len(Dright)/len(DatasetParent))*entropyRight) )
    print('entropyParent: '+str(entropyParent))
    print('SUMMATION: '+str(summation))
    gain=gain-summation
    return gain

#media=np.median((dfSubSeqDist['SubSequenceDistArray'].iloc[0]['minValueList']))
l,r=split(dfSubSeqDist['SubSequenceDistArray'].iloc[0],0.62)
#print(media)
print(l)
print('')
#print(r)
num_classes_unique=np.unique(num_classes)


l1,r1=split(l,0.45)
print(l1)
print('')
print(r1)

gain=computeGain(l,l1,r1,num_classes_unique)
print('GAIN: '+str(gain))


